{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING AND LOADING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document provides solutions to a variety of use cases regarding the saving and loading of PyTorch models. Feel free to read the whole document, or just skip to the code you need for a desired use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to saving and loading models, there are three core functions to be familiar with:\n",
    "\n",
    "- `torch.save`: Saves a serialized object to disk. This function uses Python’s `pickle` utility for serialization. Models, tensors, and dictionaries of all kinds of objects can be saved using this function.\n",
    "- `torch.load`: Uses `pickle`’s unpickling facilities to deserialize pickled object files to memory. This function also facilitates the device to load the data into (see Saving & Loading Model Across Devices).\n",
    "- `torch.nn.Module.load_state_dict`: Loads a model’s parameter dictionary using a deserialized state_dict. For more information on state_dict, see What is a state_dict?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "- What is a state_dict?\n",
    "- Saving & Loading Model for Inference\n",
    "- Saving & Loading a General Checkpoint\n",
    "- Saving Multiple Models in One File\n",
    "- Warmstarting Model Using Parameters from a Different Model\n",
    "- Saving & Loading Model Across Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a state_dict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the learnable parameters (i.e. weights and biases) of an `torch.nn.Module` model are contained in the model’s parameters (accessed with `model.parameters()`). A `state_dict` is simply a Python dictionary object that maps each layer to its parameter tensor. Note that only layers with learnable parameters (convolutional layers, linear layers, etc.) and registered buffers (batchnorm’s running_mean) have entries in the model’s state_dict. Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizer’s state, as well as the hyperparameters used.\n",
    "\n",
    "Because `state_dict` objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at the `state_dict` from the simple model used in the Training a classifier tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139860364635088, 139860364156648, 139860364211904, 139860364211976, 139860364212048, 139860364212120, 139860364212192, 139860364212264, 139860364212336, 139860364212408]}]\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class ModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Initialize model\n",
    "model = ModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 3.9920e-02,  2.3646e-02,  1.5783e-02,  1.9598e-02, -4.8225e-03],\n",
       "                        [-7.8022e-02, -5.4427e-02, -8.5006e-02, -3.1601e-02, -3.8624e-02],\n",
       "                        [ 1.1290e-01,  9.5570e-02,  7.0887e-02,  5.1470e-02, -7.9280e-02],\n",
       "                        [ 4.4184e-02, -2.9289e-02, -2.0685e-02, -3.9439e-02, -2.7586e-02],\n",
       "                        [ 3.6651e-02,  1.0946e-01,  3.5838e-02, -1.9495e-02,  3.2795e-02]],\n",
       "              \n",
       "                       [[ 6.6076e-02, -4.0654e-02, -7.3886e-02,  4.9473e-02, -8.3719e-02],\n",
       "                        [-1.1338e-01, -1.0296e-01,  3.0574e-02,  7.1579e-02,  9.0441e-02],\n",
       "                        [-4.1249e-02,  1.0479e-01,  7.3716e-02, -6.8142e-02, -1.0605e-01],\n",
       "                        [ 7.8250e-02,  8.4268e-02,  4.5055e-02, -4.1594e-02,  7.3442e-02],\n",
       "                        [ 3.7462e-02,  1.0184e-01, -4.6537e-03, -4.4809e-02,  6.5567e-02]],\n",
       "              \n",
       "                       [[ 9.5544e-02, -9.7008e-02,  8.1822e-02,  1.9924e-02, -1.1209e-01],\n",
       "                        [ 1.0327e-01,  4.7001e-02,  4.8588e-02, -9.7832e-02, -8.3952e-02],\n",
       "                        [-5.4396e-02,  9.0642e-02,  6.9358e-02,  4.8238e-02, -1.4038e-02],\n",
       "                        [ 8.3090e-02,  2.3278e-02,  7.3088e-02,  1.0531e-02, -5.7033e-02],\n",
       "                        [-3.5931e-02,  2.2290e-02,  8.6010e-02, -1.1428e-01, -5.0845e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.2113e-02, -4.9232e-02,  1.3437e-03, -4.8969e-02, -7.7607e-02],\n",
       "                        [-1.7641e-02,  3.2181e-02,  6.1243e-02,  9.0103e-02, -2.9020e-02],\n",
       "                        [-7.0612e-02,  1.1063e-01,  4.5792e-02, -3.1489e-02, -5.5022e-02],\n",
       "                        [-1.8752e-02,  8.5021e-02, -4.4347e-02,  7.5497e-02,  2.9677e-02],\n",
       "                        [ 7.0472e-02, -3.7701e-02, -6.4240e-02,  1.0570e-01, -1.2895e-02]],\n",
       "              \n",
       "                       [[ 7.5113e-02, -2.2978e-02,  5.5395e-02,  1.1003e-02, -6.0125e-02],\n",
       "                        [ 3.7768e-02,  9.9608e-02, -8.3983e-02,  1.1294e-01, -8.0746e-02],\n",
       "                        [-1.0307e-01,  1.5299e-02,  4.6810e-02,  6.3241e-02,  4.2318e-02],\n",
       "                        [-5.1896e-02, -4.5499e-02,  5.6950e-02, -7.9121e-02, -4.3722e-02],\n",
       "                        [ 7.5199e-02, -5.1975e-02,  1.1260e-02, -2.3710e-02, -2.5727e-02]],\n",
       "              \n",
       "                       [[ 6.8198e-02, -7.3689e-02,  9.3708e-02,  4.0596e-02, -7.0689e-02],\n",
       "                        [ 8.6563e-02, -6.3448e-02, -1.1083e-01, -8.3149e-02,  6.1107e-02],\n",
       "                        [-1.1532e-01,  1.8732e-02, -3.0808e-02, -3.8587e-02, -1.6440e-02],\n",
       "                        [-1.1247e-02, -1.0570e-01, -6.0597e-02, -2.0310e-02, -7.1312e-02],\n",
       "                        [ 7.2927e-02, -9.0447e-02,  7.6026e-02,  5.4490e-02, -6.7217e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.8705e-02,  1.0503e-02,  1.1336e-01,  9.3656e-02, -2.2510e-02],\n",
       "                        [ 9.9414e-02, -1.0255e-01,  1.0773e-01,  3.2933e-02,  1.0383e-01],\n",
       "                        [ 8.2848e-02, -4.4064e-02, -8.7873e-02,  5.5760e-05, -9.9389e-02],\n",
       "                        [ 1.0308e-01, -1.0453e-02,  6.2258e-02, -3.1651e-03,  8.9105e-02],\n",
       "                        [-7.5007e-04,  5.2674e-02,  7.1136e-02,  2.3491e-02,  6.1654e-02]],\n",
       "              \n",
       "                       [[-2.3550e-02,  9.1653e-02, -1.0034e-01, -4.3913e-02,  9.8073e-02],\n",
       "                        [ 6.6795e-02, -1.0015e-01,  3.5197e-02,  9.3851e-02,  9.7882e-02],\n",
       "                        [-1.0424e-01,  9.7721e-02,  7.5217e-02, -4.0851e-02,  1.9999e-02],\n",
       "                        [-6.6446e-03, -9.0635e-03, -3.4597e-02, -6.6513e-02,  8.8526e-02],\n",
       "                        [ 5.5156e-02, -6.4322e-02, -6.2384e-02, -4.2414e-02,  9.4076e-02]],\n",
       "              \n",
       "                       [[-1.9467e-02, -8.8599e-02,  6.1988e-02,  6.7201e-02, -4.3846e-04],\n",
       "                        [ 8.6301e-02,  5.4724e-03, -7.6185e-02, -6.1302e-02, -1.1082e-01],\n",
       "                        [-1.4363e-02,  3.1274e-02, -1.2421e-02,  1.0132e-01,  1.8998e-02],\n",
       "                        [-4.7812e-02,  4.0888e-02, -1.0377e-01, -1.0276e-01, -9.7234e-02],\n",
       "                        [-7.5348e-02,  2.5686e-03,  9.0993e-02, -4.5295e-02, -2.7295e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.3443e-02,  5.0945e-02, -9.1972e-02,  1.0313e-01, -3.1891e-03],\n",
       "                        [ 9.7247e-02,  6.3308e-02, -9.8772e-02,  9.2566e-03, -8.1494e-02],\n",
       "                        [ 7.7983e-02, -7.3588e-03, -5.3669e-02, -3.5480e-03, -1.0857e-01],\n",
       "                        [ 8.7038e-02, -5.7366e-02,  4.8709e-02, -2.9075e-02,  3.2269e-02],\n",
       "                        [-5.1793e-02,  9.7235e-02,  8.4316e-02, -1.0975e-01,  2.2436e-02]],\n",
       "              \n",
       "                       [[ 8.2010e-03,  1.0489e-01, -4.2005e-03,  8.7100e-02,  5.8250e-02],\n",
       "                        [ 1.0514e-01, -1.0867e-01, -8.7389e-02,  1.8855e-02,  6.4820e-02],\n",
       "                        [-1.0606e-01, -4.8672e-02,  7.3894e-02, -7.2892e-02,  1.9830e-02],\n",
       "                        [ 5.5890e-02, -8.3434e-02,  1.0762e-01, -1.1406e-01, -8.1085e-02],\n",
       "                        [-7.6387e-02,  9.3248e-02,  3.2509e-02,  2.7442e-02, -4.7938e-02]],\n",
       "              \n",
       "                       [[-9.8589e-02,  9.5400e-02, -6.7360e-02, -1.0461e-01, -9.7992e-02],\n",
       "                        [-3.7537e-02, -3.8983e-02, -8.7893e-02,  5.3291e-02, -3.3379e-02],\n",
       "                        [-1.0887e-01, -9.3355e-02,  6.2600e-02,  1.1524e-01,  1.5604e-03],\n",
       "                        [ 9.6481e-03, -2.5898e-02,  1.0453e-02,  8.8490e-02, -1.7518e-02],\n",
       "                        [-4.2444e-02,  7.8601e-02, -1.1183e-01, -8.8386e-02,  2.6924e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6898e-02, -1.6179e-02,  3.2188e-02, -1.1080e-01,  7.0991e-03],\n",
       "                        [-1.1220e-01, -1.0757e-01, -1.2107e-02,  1.1486e-01,  1.3628e-02],\n",
       "                        [ 7.3839e-02,  4.3586e-02, -1.2859e-03,  7.1402e-02,  4.4012e-02],\n",
       "                        [-1.1446e-01, -1.0228e-01, -1.2748e-02,  1.0660e-01, -8.4620e-02],\n",
       "                        [-5.0898e-02,  4.6910e-02,  8.6737e-02, -2.8282e-02,  1.1367e-01]],\n",
       "              \n",
       "                       [[-3.2592e-02, -4.0286e-02,  9.6598e-02,  7.2709e-02,  6.4806e-02],\n",
       "                        [ 7.4569e-03,  1.0231e-01,  6.6901e-02, -3.0555e-02, -3.0903e-02],\n",
       "                        [ 3.0650e-02,  6.2355e-02,  5.6042e-02,  5.8934e-03,  3.7705e-02],\n",
       "                        [ 5.9428e-02, -2.7345e-02, -5.0109e-02,  8.5547e-02, -9.0860e-02],\n",
       "                        [-9.6696e-02,  4.9259e-02, -9.8192e-02, -6.4304e-02,  6.3120e-02]],\n",
       "              \n",
       "                       [[-1.5219e-02,  7.3774e-02, -2.4356e-02,  2.8094e-02,  5.8394e-02],\n",
       "                        [ 7.8331e-02, -1.0843e-03,  2.4402e-02, -1.1005e-01,  7.1008e-02],\n",
       "                        [ 1.4541e-02,  5.3316e-02,  1.5198e-02,  4.2745e-02,  1.0103e-01],\n",
       "                        [-2.0757e-02, -5.7382e-02, -5.4714e-02,  3.7298e-03,  6.4219e-02],\n",
       "                        [-1.1151e-01,  1.1168e-01,  9.4596e-02, -1.5517e-02, -4.2053e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.8526e-02,  1.0721e-01,  8.7379e-02, -1.1218e-01,  9.6859e-02],\n",
       "                        [ 8.9711e-02, -4.9569e-02, -1.0024e-02, -2.3402e-02,  2.5370e-02],\n",
       "                        [ 1.1918e-02, -1.1168e-01,  1.0009e-01, -3.2103e-02, -1.8311e-02],\n",
       "                        [ 8.1371e-02, -8.2244e-02,  4.5358e-02,  2.6023e-02, -8.6585e-02],\n",
       "                        [-1.1301e-03,  1.1383e-01,  4.3583e-02,  4.9009e-02, -4.9796e-02]],\n",
       "              \n",
       "                       [[-8.1684e-04,  9.7680e-02, -1.1265e-01,  3.3763e-02, -8.0528e-02],\n",
       "                        [-9.1817e-02, -4.0870e-02,  9.5507e-02,  1.0669e-01,  5.7669e-02],\n",
       "                        [-6.5560e-02,  3.1971e-02,  3.2421e-02, -1.0735e-02,  2.4926e-02],\n",
       "                        [ 1.0789e-01, -3.6180e-02, -6.1926e-02, -3.3477e-02, -8.2424e-02],\n",
       "                        [-9.2241e-02,  7.7002e-02,  9.2368e-02, -5.9078e-02, -7.2283e-02]],\n",
       "              \n",
       "                       [[-7.5298e-02,  4.3127e-02,  9.5957e-02, -1.5224e-02, -6.9694e-02],\n",
       "                        [-1.1011e-02,  3.6307e-02, -9.0034e-02, -5.7855e-02,  1.0020e-01],\n",
       "                        [ 6.4839e-02, -1.8166e-02,  4.6208e-02, -7.0029e-02,  4.1566e-02],\n",
       "                        [ 6.1793e-03,  8.4749e-02,  9.8323e-02, -1.6219e-02, -1.1425e-01],\n",
       "                        [-7.7678e-02, -1.0799e-01,  5.9366e-02, -1.0292e-01, -4.9150e-03]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.1015, -0.1104,  0.0059, -0.1109, -0.0878,  0.0404])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 0.0731,  0.0706,  0.0044,  0.0606,  0.0280],\n",
       "                        [-0.0467, -0.0576,  0.0690,  0.0300, -0.0519],\n",
       "                        [-0.0413, -0.0324, -0.0491,  0.0151, -0.0578],\n",
       "                        [ 0.0257, -0.0420, -0.0078, -0.0567, -0.0207],\n",
       "                        [ 0.0188,  0.0641, -0.0710, -0.0131, -0.0365]],\n",
       "              \n",
       "                       [[-0.0243, -0.0689, -0.0804,  0.0177,  0.0728],\n",
       "                        [-0.0592, -0.0765, -0.0532, -0.0079,  0.0033],\n",
       "                        [ 0.0094,  0.0623,  0.0222, -0.0708,  0.0354],\n",
       "                        [-0.0538,  0.0387,  0.0314,  0.0253,  0.0036],\n",
       "                        [ 0.0416, -0.0518, -0.0488, -0.0802,  0.0623]],\n",
       "              \n",
       "                       [[-0.0455,  0.0528, -0.0542, -0.0753,  0.0294],\n",
       "                        [ 0.0328,  0.0007, -0.0754, -0.0475,  0.0441],\n",
       "                        [ 0.0684, -0.0257,  0.0517, -0.0683,  0.0311],\n",
       "                        [-0.0424, -0.0182, -0.0432,  0.0432,  0.0172],\n",
       "                        [ 0.0090,  0.0676, -0.0286,  0.0770, -0.0652]],\n",
       "              \n",
       "                       [[-0.0105, -0.0490,  0.0318, -0.0799, -0.0104],\n",
       "                        [-0.0682,  0.0705, -0.0545,  0.0732, -0.0712],\n",
       "                        [-0.0605,  0.0317,  0.0067,  0.0803, -0.0532],\n",
       "                        [-0.0125,  0.0755, -0.0699, -0.0547, -0.0405],\n",
       "                        [ 0.0792,  0.0498, -0.0408, -0.0064,  0.0433]],\n",
       "              \n",
       "                       [[-0.0329, -0.0695,  0.0525,  0.0508, -0.0541],\n",
       "                        [-0.0284, -0.0639, -0.0677,  0.0792, -0.0457],\n",
       "                        [-0.0773,  0.0120,  0.0435,  0.0391, -0.0783],\n",
       "                        [-0.0746,  0.0364,  0.0574,  0.0789, -0.0071],\n",
       "                        [-0.0131, -0.0676,  0.0312,  0.0604,  0.0112]],\n",
       "              \n",
       "                       [[ 0.0210,  0.0478, -0.0089,  0.0187, -0.0594],\n",
       "                        [-0.0812, -0.0276, -0.0757,  0.0368, -0.0503],\n",
       "                        [-0.0493, -0.0816, -0.0791,  0.0011,  0.0225],\n",
       "                        [-0.0495,  0.0639, -0.0295, -0.0356, -0.0542],\n",
       "                        [ 0.0552, -0.0185,  0.0669,  0.0403,  0.0693]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0431, -0.0616, -0.0224,  0.0405,  0.0778],\n",
       "                        [ 0.0388, -0.0673, -0.0243,  0.0640, -0.0228],\n",
       "                        [ 0.0309,  0.0091, -0.0148, -0.0366,  0.0483],\n",
       "                        [-0.0280,  0.0643, -0.0319, -0.0712, -0.0032],\n",
       "                        [-0.0614, -0.0564, -0.0534, -0.0271, -0.0803]],\n",
       "              \n",
       "                       [[-0.0395, -0.0581,  0.0259,  0.0774,  0.0052],\n",
       "                        [ 0.0380,  0.0400, -0.0402, -0.0404,  0.0002],\n",
       "                        [ 0.0736, -0.0411,  0.0328,  0.0433,  0.0522],\n",
       "                        [ 0.0566,  0.0783,  0.0716, -0.0575, -0.0394],\n",
       "                        [ 0.0303, -0.0231,  0.0012,  0.0183,  0.0131]],\n",
       "              \n",
       "                       [[ 0.0660, -0.0711,  0.0140, -0.0444, -0.0238],\n",
       "                        [-0.0241, -0.0256, -0.0635,  0.0714, -0.0691],\n",
       "                        [ 0.0803, -0.0556,  0.0028,  0.0322,  0.0539],\n",
       "                        [-0.0053,  0.0619, -0.0453, -0.0540,  0.0488],\n",
       "                        [ 0.0583,  0.0562,  0.0608, -0.0695, -0.0765]],\n",
       "              \n",
       "                       [[-0.0740, -0.0549,  0.0233, -0.0798,  0.0202],\n",
       "                        [ 0.0728, -0.0079, -0.0426, -0.0345, -0.0360],\n",
       "                        [ 0.0304,  0.0573,  0.0815,  0.0079,  0.0037],\n",
       "                        [ 0.0740,  0.0014,  0.0754, -0.0688,  0.0209],\n",
       "                        [-0.0687,  0.0032,  0.0407,  0.0605,  0.0296]],\n",
       "              \n",
       "                       [[ 0.0743, -0.0757,  0.0706,  0.0262, -0.0159],\n",
       "                        [ 0.0142,  0.0713,  0.0338,  0.0515,  0.0484],\n",
       "                        [-0.0551,  0.0501, -0.0088, -0.0729,  0.0532],\n",
       "                        [-0.0750,  0.0486,  0.0588,  0.0611,  0.0553],\n",
       "                        [ 0.0788,  0.0315,  0.0678, -0.0186,  0.0262]],\n",
       "              \n",
       "                       [[-0.0620,  0.0433,  0.0347,  0.0363,  0.0614],\n",
       "                        [ 0.0062,  0.0019,  0.0057, -0.0725,  0.0646],\n",
       "                        [-0.0560, -0.0551,  0.0736, -0.0612,  0.0633],\n",
       "                        [-0.0180,  0.0639, -0.0772,  0.0539,  0.0551],\n",
       "                        [-0.0556, -0.0234, -0.0583,  0.0270,  0.0434]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0795,  0.0517, -0.0616,  0.0613,  0.0593],\n",
       "                        [-0.0189,  0.0285,  0.0204,  0.0455,  0.0764],\n",
       "                        [-0.0655,  0.0649, -0.0580,  0.0161,  0.0766],\n",
       "                        [ 0.0738,  0.0348,  0.0564, -0.0157,  0.0729],\n",
       "                        [ 0.0405,  0.0462, -0.0470,  0.0413,  0.0424]],\n",
       "              \n",
       "                       [[ 0.0193, -0.0115, -0.0612,  0.0070, -0.0640],\n",
       "                        [ 0.0523,  0.0513,  0.0081, -0.0132,  0.0010],\n",
       "                        [ 0.0774,  0.0687,  0.0681,  0.0789,  0.0624],\n",
       "                        [-0.0727, -0.0476,  0.0050, -0.0139, -0.0736],\n",
       "                        [ 0.0579,  0.0226, -0.0308,  0.0722, -0.0169]],\n",
       "              \n",
       "                       [[-0.0002, -0.0608, -0.0706,  0.0708, -0.0138],\n",
       "                        [-0.0329, -0.0032, -0.0077,  0.0793,  0.0008],\n",
       "                        [ 0.0445,  0.0243,  0.0583, -0.0509, -0.0430],\n",
       "                        [-0.0803,  0.0106,  0.0359,  0.0678,  0.0108],\n",
       "                        [-0.0589, -0.0653, -0.0438, -0.0100,  0.0181]],\n",
       "              \n",
       "                       [[-0.0177, -0.0284,  0.0001,  0.0513, -0.0119],\n",
       "                        [ 0.0576,  0.0753,  0.0662, -0.0287, -0.0658],\n",
       "                        [ 0.0038, -0.0749,  0.0204, -0.0505, -0.0255],\n",
       "                        [-0.0463,  0.0366,  0.0348, -0.0288, -0.0753],\n",
       "                        [-0.0765,  0.0752,  0.0063,  0.0728, -0.0569]],\n",
       "              \n",
       "                       [[-0.0210, -0.0612,  0.0508, -0.0171,  0.0373],\n",
       "                        [ 0.0671, -0.0202, -0.0309, -0.0363,  0.0529],\n",
       "                        [ 0.0176, -0.0601,  0.0194,  0.0740, -0.0472],\n",
       "                        [ 0.0116, -0.0192, -0.0198,  0.0103, -0.0008],\n",
       "                        [-0.0727,  0.0086, -0.0765,  0.0376, -0.0167]],\n",
       "              \n",
       "                       [[ 0.0575, -0.0668,  0.0727,  0.0337, -0.0482],\n",
       "                        [ 0.0722,  0.0288,  0.0214,  0.0749,  0.0208],\n",
       "                        [-0.0028, -0.0221,  0.0217, -0.0150, -0.0617],\n",
       "                        [ 0.0558,  0.0565,  0.0203, -0.0741,  0.0776],\n",
       "                        [ 0.0787,  0.0530, -0.0635,  0.0147,  0.0799]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0083, -0.0022,  0.0332,  0.0457,  0.0441],\n",
       "                        [-0.0665, -0.0718,  0.0532, -0.0029,  0.0581],\n",
       "                        [ 0.0371,  0.0023, -0.0125, -0.0315,  0.0411],\n",
       "                        [-0.0473,  0.0518,  0.0764, -0.0009,  0.0162],\n",
       "                        [ 0.0808,  0.0111,  0.0177,  0.0345,  0.0628]],\n",
       "              \n",
       "                       [[ 0.0082,  0.0598,  0.0037,  0.0219,  0.0055],\n",
       "                        [-0.0354,  0.0091,  0.0727, -0.0219, -0.0166],\n",
       "                        [-0.0314, -0.0487, -0.0446,  0.0376,  0.0172],\n",
       "                        [ 0.0288,  0.0199,  0.0640,  0.0193, -0.0223],\n",
       "                        [ 0.0419, -0.0251,  0.0272, -0.0113, -0.0182]],\n",
       "              \n",
       "                       [[-0.0386, -0.0756, -0.0583, -0.0589, -0.0391],\n",
       "                        [ 0.0479, -0.0481, -0.0345, -0.0040, -0.0363],\n",
       "                        [-0.0002, -0.0738, -0.0226,  0.0138, -0.0421],\n",
       "                        [-0.0374, -0.0815,  0.0271, -0.0529, -0.0362],\n",
       "                        [-0.0441, -0.0184, -0.0047, -0.0211, -0.0449]],\n",
       "              \n",
       "                       [[ 0.0720,  0.0509,  0.0256,  0.0381, -0.0401],\n",
       "                        [ 0.0513, -0.0008,  0.0111, -0.0507, -0.0484],\n",
       "                        [-0.0586, -0.0517, -0.0756,  0.0340, -0.0525],\n",
       "                        [ 0.0314, -0.0707, -0.0197, -0.0692, -0.0034],\n",
       "                        [ 0.0083,  0.0276,  0.0186, -0.0413, -0.0575]],\n",
       "              \n",
       "                       [[-0.0357, -0.0725,  0.0551, -0.0645,  0.0357],\n",
       "                        [-0.0450,  0.0333, -0.0615, -0.0299,  0.0634],\n",
       "                        [ 0.0782,  0.0468, -0.0697,  0.0601, -0.0809],\n",
       "                        [ 0.0004, -0.0654, -0.0033, -0.0339,  0.0623],\n",
       "                        [ 0.0548, -0.0679, -0.0185,  0.0376,  0.0721]],\n",
       "              \n",
       "                       [[ 0.0346, -0.0810,  0.0754, -0.0033, -0.0591],\n",
       "                        [ 0.0536,  0.0421, -0.0501, -0.0491, -0.0484],\n",
       "                        [ 0.0595,  0.0036, -0.0310, -0.0417,  0.0192],\n",
       "                        [ 0.0598,  0.0230, -0.0218,  0.0323,  0.0807],\n",
       "                        [ 0.0541, -0.0182, -0.0465,  0.0590, -0.0332]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0689, -0.0662,  0.0551,  0.0439, -0.0573],\n",
       "                        [ 0.0361, -0.0731, -0.0782,  0.0455, -0.0244],\n",
       "                        [-0.0339, -0.0608, -0.0433,  0.0121, -0.0454],\n",
       "                        [-0.0083, -0.0805, -0.0601, -0.0540,  0.0348],\n",
       "                        [ 0.0079,  0.0592,  0.0409, -0.0516,  0.0772]],\n",
       "              \n",
       "                       [[-0.0218, -0.0204,  0.0306,  0.0720, -0.0607],\n",
       "                        [ 0.0766,  0.0391, -0.0346,  0.0318, -0.0541],\n",
       "                        [ 0.0242,  0.0452, -0.0484, -0.0758, -0.0387],\n",
       "                        [ 0.0695,  0.0276,  0.0683,  0.0555,  0.0088],\n",
       "                        [-0.0252,  0.0458,  0.0287, -0.0790, -0.0734]],\n",
       "              \n",
       "                       [[ 0.0658, -0.0119,  0.0376,  0.0384,  0.0033],\n",
       "                        [ 0.0067, -0.0499,  0.0081, -0.0489,  0.0456],\n",
       "                        [-0.0616,  0.0335,  0.0662, -0.0281, -0.0018],\n",
       "                        [-0.0284, -0.0654, -0.0018,  0.0346, -0.0445],\n",
       "                        [ 0.0085,  0.0218, -0.0776,  0.0439,  0.0453]],\n",
       "              \n",
       "                       [[-0.0187, -0.0104, -0.0114, -0.0435, -0.0385],\n",
       "                        [ 0.0239,  0.0433, -0.0753, -0.0214,  0.0327],\n",
       "                        [ 0.0470, -0.0220, -0.0724, -0.0108,  0.0363],\n",
       "                        [-0.0648, -0.0756, -0.0554, -0.0359,  0.0413],\n",
       "                        [ 0.0251, -0.0131,  0.0194, -0.0084, -0.0422]],\n",
       "              \n",
       "                       [[-0.0796, -0.0371,  0.0151,  0.0383, -0.0136],\n",
       "                        [-0.0635, -0.0806, -0.0328, -0.0705, -0.0605],\n",
       "                        [ 0.0608,  0.0440, -0.0039, -0.0275, -0.0555],\n",
       "                        [ 0.0802,  0.0221, -0.0784, -0.0507,  0.0440],\n",
       "                        [ 0.0030, -0.0619,  0.0684,  0.0748,  0.0654]],\n",
       "              \n",
       "                       [[-0.0030,  0.0355,  0.0068, -0.0432,  0.0512],\n",
       "                        [ 0.0719, -0.0287, -0.0230, -0.0437, -0.0127],\n",
       "                        [-0.0230, -0.0484, -0.0431,  0.0647,  0.0400],\n",
       "                        [ 0.0640, -0.0505, -0.0229,  0.0312,  0.0483],\n",
       "                        [-0.0482,  0.0122,  0.0074, -0.0029,  0.0156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0732, -0.0760,  0.0577, -0.0766, -0.0483],\n",
       "                        [ 0.0672, -0.0525,  0.0417, -0.0609, -0.0173],\n",
       "                        [ 0.0500,  0.0307,  0.0482, -0.0651,  0.0502],\n",
       "                        [ 0.0140,  0.0337, -0.0456, -0.0059,  0.0759],\n",
       "                        [ 0.0126,  0.0291, -0.0418,  0.0356,  0.0029]],\n",
       "              \n",
       "                       [[ 0.0162, -0.0264, -0.0297, -0.0360,  0.0043],\n",
       "                        [-0.0166,  0.0285, -0.0452,  0.0765, -0.0783],\n",
       "                        [ 0.0558, -0.0188, -0.0393, -0.0342, -0.0258],\n",
       "                        [-0.0312, -0.0012, -0.0289, -0.0147, -0.0237],\n",
       "                        [ 0.0143,  0.0033,  0.0484,  0.0606, -0.0269]],\n",
       "              \n",
       "                       [[-0.0585,  0.0013, -0.0644,  0.0632, -0.0770],\n",
       "                        [ 0.0203,  0.0472,  0.0104, -0.0602, -0.0727],\n",
       "                        [-0.0631, -0.0524, -0.0554, -0.0056, -0.0680],\n",
       "                        [-0.0481, -0.0151,  0.0784, -0.0697,  0.0462],\n",
       "                        [-0.0027, -0.0227, -0.0753, -0.0544, -0.0746]],\n",
       "              \n",
       "                       [[-0.0740,  0.0012, -0.0756,  0.0391,  0.0679],\n",
       "                        [ 0.0225, -0.0283,  0.0355,  0.0149,  0.0804],\n",
       "                        [-0.0004,  0.0470, -0.0097,  0.0186,  0.0396],\n",
       "                        [-0.0333, -0.0759,  0.0030, -0.0031, -0.0391],\n",
       "                        [-0.0484,  0.0815,  0.0166, -0.0518, -0.0614]],\n",
       "              \n",
       "                       [[-0.0079,  0.0448, -0.0650,  0.0356,  0.0450],\n",
       "                        [-0.0475,  0.0007,  0.0696,  0.0211,  0.0441],\n",
       "                        [ 0.0777,  0.0713, -0.0178,  0.0085,  0.0302],\n",
       "                        [-0.0456, -0.0449,  0.0040, -0.0451,  0.0473],\n",
       "                        [ 0.0210,  0.0729, -0.0092,  0.0253,  0.0139]],\n",
       "              \n",
       "                       [[ 0.0774, -0.0812, -0.0723,  0.0516, -0.0675],\n",
       "                        [ 0.0272,  0.0471,  0.0147, -0.0291,  0.0489],\n",
       "                        [-0.0435, -0.0007,  0.0668, -0.0505, -0.0675],\n",
       "                        [-0.0283,  0.0239, -0.0141, -0.0660, -0.0510],\n",
       "                        [-0.0126, -0.0235,  0.0511,  0.0801,  0.0569]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.0405, -0.0710,  0.0769, -0.0256, -0.0811, -0.0535,  0.0266, -0.0452,\n",
       "                      -0.0405, -0.0162, -0.0535, -0.0241,  0.0581, -0.0701,  0.0570,  0.0621])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0497,  0.0011, -0.0296,  ..., -0.0097,  0.0446,  0.0460],\n",
       "                      [ 0.0120,  0.0101, -0.0049,  ...,  0.0323,  0.0036, -0.0406],\n",
       "                      [ 0.0133,  0.0062,  0.0252,  ..., -0.0018, -0.0407, -0.0351],\n",
       "                      ...,\n",
       "                      [ 0.0149,  0.0193, -0.0429,  ...,  0.0214,  0.0394,  0.0165],\n",
       "                      [ 0.0323, -0.0434, -0.0048,  ...,  0.0155,  0.0365,  0.0038],\n",
       "                      [ 0.0103,  0.0129,  0.0147,  ..., -0.0465,  0.0363, -0.0482]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0103,  0.0256, -0.0410, -0.0355, -0.0407,  0.0291,  0.0071,  0.0249,\n",
       "                      -0.0440,  0.0246,  0.0211, -0.0259,  0.0035, -0.0293,  0.0114,  0.0342,\n",
       "                      -0.0089, -0.0117, -0.0467, -0.0022, -0.0405, -0.0354,  0.0221,  0.0075,\n",
       "                      -0.0106,  0.0071,  0.0306, -0.0420, -0.0291, -0.0483,  0.0299, -0.0214,\n",
       "                      -0.0042,  0.0343,  0.0183, -0.0437,  0.0343,  0.0283, -0.0384, -0.0256,\n",
       "                       0.0192,  0.0382,  0.0201, -0.0421,  0.0245, -0.0128, -0.0354,  0.0252,\n",
       "                       0.0484, -0.0273, -0.0211,  0.0043, -0.0260, -0.0489, -0.0069, -0.0434,\n",
       "                      -0.0389,  0.0399,  0.0275,  0.0115, -0.0371, -0.0171, -0.0193,  0.0297,\n",
       "                      -0.0419,  0.0240,  0.0132, -0.0169, -0.0214,  0.0110, -0.0135,  0.0478,\n",
       "                       0.0256, -0.0429,  0.0043,  0.0349, -0.0199,  0.0244,  0.0238,  0.0126,\n",
       "                       0.0293, -0.0371, -0.0191, -0.0175,  0.0199,  0.0145,  0.0047, -0.0234,\n",
       "                      -0.0443,  0.0259, -0.0274,  0.0352,  0.0051,  0.0109,  0.0277,  0.0230,\n",
       "                      -0.0361, -0.0278,  0.0256, -0.0479, -0.0269, -0.0344, -0.0160,  0.0108,\n",
       "                       0.0208, -0.0398,  0.0198,  0.0212, -0.0239,  0.0195,  0.0485,  0.0160,\n",
       "                       0.0411,  0.0383,  0.0486, -0.0060, -0.0191,  0.0372, -0.0055, -0.0190])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0467, -0.0346, -0.0366,  ..., -0.0550, -0.0169, -0.0253],\n",
       "                      [-0.0007,  0.0006,  0.0726,  ...,  0.0497,  0.0175,  0.0029],\n",
       "                      [ 0.0642,  0.0206, -0.0142,  ...,  0.0330, -0.0382, -0.0705],\n",
       "                      ...,\n",
       "                      [-0.0272,  0.0860,  0.0474,  ..., -0.0409, -0.0497,  0.0330],\n",
       "                      [ 0.0217,  0.0398,  0.0857,  ..., -0.0533, -0.0416,  0.0585],\n",
       "                      [ 0.0016, -0.0348,  0.0458,  ...,  0.0054,  0.0479, -0.0795]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0547, -0.0650,  0.0200, -0.0467,  0.0351, -0.0571, -0.0876,  0.0044,\n",
       "                       0.0477, -0.0792,  0.0027,  0.0608,  0.0037,  0.0234, -0.0198, -0.0047,\n",
       "                      -0.0249, -0.0556,  0.0843, -0.0667, -0.0458,  0.0677,  0.0409,  0.0786,\n",
       "                       0.0743, -0.0002, -0.0787, -0.0155,  0.0362,  0.0640, -0.0376, -0.0448,\n",
       "                       0.0522, -0.0877, -0.0563,  0.0507,  0.0659, -0.0739,  0.0606,  0.0745,\n",
       "                       0.0104,  0.0370,  0.0795, -0.0002, -0.0304, -0.0748, -0.0790,  0.0411,\n",
       "                      -0.0716, -0.0125,  0.0482,  0.0435, -0.0830,  0.0850, -0.0874,  0.0763,\n",
       "                       0.0618, -0.0060,  0.0701,  0.0590, -0.0472,  0.0631,  0.0538, -0.0755,\n",
       "                      -0.0549, -0.0150, -0.0184, -0.0035,  0.0298, -0.0046, -0.0156,  0.0517,\n",
       "                       0.0351,  0.0335, -0.0003,  0.0242,  0.0710,  0.0097,  0.0600, -0.0099,\n",
       "                      -0.0837, -0.0102,  0.0668,  0.0575])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 3.8428e-02,  1.0887e-01,  6.5940e-03,  4.7847e-02,  1.7448e-02,\n",
       "                        1.2496e-02,  1.2754e-02,  3.1010e-02,  9.4694e-02, -6.8648e-02,\n",
       "                       -3.6146e-02,  9.5746e-02, -1.0165e-01,  6.6383e-03,  9.6412e-02,\n",
       "                       -3.2068e-02, -9.8600e-02, -6.4062e-02, -7.7489e-02,  1.0625e-01,\n",
       "                       -9.7520e-03, -4.3239e-02, -1.2191e-02, -9.9170e-02,  8.4884e-02,\n",
       "                       -4.1984e-02,  2.8793e-02,  4.5856e-02,  9.1886e-02, -5.8662e-03,\n",
       "                        6.9220e-02,  1.1202e-02,  3.4389e-03, -2.1395e-02,  5.5207e-02,\n",
       "                        1.0107e-01, -5.2403e-02, -8.9410e-02,  7.0868e-02,  5.5401e-02,\n",
       "                       -9.8375e-02, -9.6263e-02, -1.0008e-02,  3.0619e-02,  2.2741e-02,\n",
       "                       -5.3040e-02,  8.5109e-02,  6.2888e-02,  1.0346e-01, -3.2475e-02,\n",
       "                        7.1055e-02, -4.8385e-02,  2.3697e-02,  1.4040e-02,  6.7320e-02,\n",
       "                        3.4548e-02,  1.0201e-01,  2.2480e-03, -7.2642e-03,  2.9001e-03,\n",
       "                        1.1637e-02,  9.3546e-02, -2.0758e-02,  3.7962e-02, -1.0279e-01,\n",
       "                       -5.1415e-02,  5.6948e-02, -1.0438e-01, -7.4085e-02, -3.2902e-02,\n",
       "                       -6.9741e-02,  6.8029e-02, -1.0800e-01,  5.4001e-02,  3.9649e-02,\n",
       "                        2.0845e-02, -1.4304e-02, -4.4552e-02, -1.2917e-02, -9.0942e-02,\n",
       "                       -8.9575e-02, -8.9111e-02, -9.8937e-02,  8.8001e-02],\n",
       "                      [ 6.7848e-02,  3.7853e-02,  7.3562e-03,  5.5680e-02,  6.5847e-02,\n",
       "                       -1.7874e-02, -1.0812e-01,  9.8274e-02,  6.1233e-02, -5.8340e-02,\n",
       "                        1.1205e-02,  5.4362e-03,  2.7631e-02, -1.0657e-01, -9.5627e-02,\n",
       "                       -3.3045e-02,  1.0503e-02, -8.4739e-02,  9.8835e-02, -5.3405e-02,\n",
       "                        1.0552e-01, -2.9969e-02,  4.3506e-02,  5.9283e-02,  2.6740e-03,\n",
       "                       -4.2623e-02, -9.8300e-02, -9.4572e-02,  5.5666e-03,  7.9422e-02,\n",
       "                       -1.5963e-02, -2.0104e-02,  6.6791e-02, -4.8213e-02,  3.9785e-02,\n",
       "                        3.4126e-02, -3.3338e-02, -7.6735e-02,  3.1039e-02, -5.8261e-03,\n",
       "                       -2.5990e-02, -7.2304e-02,  9.9765e-02, -6.5847e-02,  3.0478e-02,\n",
       "                       -5.2912e-03,  1.2854e-02,  8.0751e-02,  1.0960e-02,  1.0075e-01,\n",
       "                       -8.7914e-02, -2.4444e-02, -7.3659e-02, -1.0380e-01, -6.7989e-02,\n",
       "                        4.5621e-02, -4.4149e-02,  4.1467e-02,  1.0036e-01,  3.9874e-02,\n",
       "                        1.0263e-01, -3.9132e-02, -9.1376e-03, -6.6321e-02,  1.0430e-01,\n",
       "                       -1.0911e-01,  4.5690e-02,  5.5989e-02, -1.1284e-02,  5.0350e-02,\n",
       "                        1.5590e-02,  8.5733e-02, -3.2312e-02, -9.5637e-02,  7.5507e-02,\n",
       "                        7.6556e-02, -4.8968e-02,  5.7799e-02,  3.0178e-02, -4.9803e-02,\n",
       "                        8.6872e-02,  1.3964e-02,  9.4184e-03,  1.0403e-02],\n",
       "                      [-7.2122e-02, -4.4429e-02,  8.7694e-02, -7.2279e-02,  1.5203e-02,\n",
       "                        8.9114e-02,  5.2425e-02,  5.6397e-02, -2.5372e-02, -8.1279e-04,\n",
       "                        2.9516e-02, -8.8061e-02, -2.8349e-02,  5.5279e-02,  6.9945e-02,\n",
       "                        2.4355e-03,  5.4633e-02, -3.9629e-02, -1.0261e-01,  7.6621e-03,\n",
       "                       -6.2385e-02, -1.4107e-02, -3.9457e-03,  9.2925e-02, -8.3826e-02,\n",
       "                       -7.0307e-02, -6.2952e-02, -7.2936e-02, -4.2112e-02, -9.6734e-02,\n",
       "                       -5.6162e-02,  1.5519e-02, -5.9302e-02,  5.6143e-02,  1.4817e-02,\n",
       "                       -1.0153e-01, -1.3547e-02,  2.9767e-02, -7.7743e-02,  8.8284e-02,\n",
       "                        6.5323e-02,  5.0074e-02, -8.8176e-02, -8.2048e-02,  3.5267e-02,\n",
       "                       -6.0736e-02,  6.2247e-03, -1.0309e-01,  6.0937e-02, -6.6308e-03,\n",
       "                       -1.8513e-02, -3.6264e-02, -3.3210e-02,  9.4383e-02, -8.9248e-02,\n",
       "                       -3.6887e-02,  6.4615e-02, -6.7842e-02, -1.0425e-01,  3.0094e-02,\n",
       "                        2.3857e-02, -3.4542e-03, -2.7693e-02, -1.0426e-01, -7.2054e-02,\n",
       "                        3.3368e-03, -7.3494e-02, -4.2219e-02, -2.9221e-02, -3.9743e-02,\n",
       "                        7.2392e-02, -1.3736e-02,  6.3234e-03,  7.5660e-02, -7.3344e-02,\n",
       "                       -4.5719e-02, -8.7022e-02, -9.3798e-02, -2.7907e-02,  3.0633e-02,\n",
       "                        6.2706e-02, -2.9499e-03, -6.0165e-02,  2.9395e-02],\n",
       "                      [-9.5240e-02,  9.4768e-02, -9.9154e-02, -9.4763e-02,  6.3776e-02,\n",
       "                        4.7044e-02,  6.7295e-02,  8.8645e-02,  6.4589e-02, -5.4529e-02,\n",
       "                       -1.0296e-01, -3.7209e-02,  2.2666e-02,  1.0878e-01,  2.0818e-02,\n",
       "                        1.0439e-01, -9.3848e-02, -3.2767e-02,  4.0098e-02,  3.3352e-02,\n",
       "                       -3.8353e-02,  3.8828e-02, -1.9764e-02,  1.0152e-02, -1.0699e-02,\n",
       "                        1.5803e-02, -4.8173e-02,  1.0698e-02, -1.0611e-01,  1.0656e-01,\n",
       "                       -3.5283e-02, -1.7833e-02,  6.4750e-02,  3.5829e-02,  7.5745e-02,\n",
       "                       -9.4357e-03, -5.8189e-02,  1.3856e-02, -9.6092e-02, -9.0460e-02,\n",
       "                       -8.4048e-02, -7.4854e-02,  3.1909e-03,  2.6120e-03, -9.6760e-02,\n",
       "                       -9.4196e-02, -9.6101e-02, -9.6443e-02, -6.0217e-02, -1.6693e-03,\n",
       "                       -5.5542e-02, -8.0412e-02, -9.1046e-02,  2.0427e-03,  2.7819e-03,\n",
       "                        9.7862e-02,  1.3743e-02, -2.8238e-02, -2.4870e-02,  8.2893e-02,\n",
       "                       -6.8910e-02, -9.4841e-02, -7.0838e-02, -1.0278e-01, -2.9541e-02,\n",
       "                        8.8697e-02, -4.1115e-02, -1.0203e-01,  1.0058e-01,  1.0420e-01,\n",
       "                       -1.1828e-02,  7.5957e-02, -4.7689e-02,  1.8539e-03,  7.2759e-02,\n",
       "                       -3.6748e-02, -8.8522e-02, -1.5001e-02,  5.6941e-02, -9.4926e-04,\n",
       "                        7.8895e-02, -1.3916e-02,  6.7300e-02, -6.5955e-02],\n",
       "                      [ 5.5348e-02, -6.4565e-02,  3.9508e-02,  9.1073e-02,  8.9641e-02,\n",
       "                        3.7554e-02, -2.3942e-02, -6.5070e-02, -3.6252e-02,  3.8611e-02,\n",
       "                        2.9304e-02, -6.3991e-02, -1.9190e-03, -4.2359e-02,  2.2291e-02,\n",
       "                       -3.3475e-02, -8.2070e-02,  8.4210e-03,  3.9640e-02,  5.2782e-02,\n",
       "                       -8.8731e-02, -9.3609e-02,  8.9368e-03,  1.5605e-02,  5.8803e-02,\n",
       "                       -8.6470e-02, -6.8927e-02, -2.5445e-02, -1.5407e-02, -4.4615e-02,\n",
       "                       -1.1513e-02,  2.6429e-02, -5.3956e-02,  2.0272e-02,  9.3830e-02,\n",
       "                        1.3507e-02, -7.3978e-02,  2.6024e-02,  8.6987e-02,  7.6558e-02,\n",
       "                       -7.9210e-02, -3.0669e-02, -2.4706e-02,  2.8210e-02, -1.2393e-02,\n",
       "                        1.3137e-02, -1.9322e-02,  3.2241e-02,  3.2621e-02,  3.6933e-02,\n",
       "                        1.0337e-02, -5.6331e-02,  3.4334e-02, -9.0363e-03,  1.0452e-01,\n",
       "                        3.6176e-02, -2.2115e-02, -3.2001e-02, -1.0012e-01,  3.2467e-03,\n",
       "                        7.1837e-03,  4.4466e-02,  4.0307e-02, -9.9572e-02,  5.4044e-02,\n",
       "                        3.2036e-02,  1.2539e-05, -8.0896e-03, -8.3747e-02,  2.1224e-02,\n",
       "                       -6.4803e-02, -7.7199e-02, -9.8606e-02,  1.0711e-01,  7.6650e-02,\n",
       "                        7.5492e-02, -5.9654e-02,  5.1069e-02, -7.9282e-02, -1.9308e-02,\n",
       "                        3.2049e-02,  2.0757e-02,  5.0966e-02,  6.8876e-02],\n",
       "                      [-5.4533e-02, -8.5599e-02, -4.0263e-03, -1.4789e-02, -3.9557e-04,\n",
       "                       -5.1717e-02,  3.1941e-02,  6.8960e-03,  8.5356e-02, -5.4902e-02,\n",
       "                        7.4645e-02,  4.8164e-02, -1.8984e-02, -3.8145e-03, -2.1568e-03,\n",
       "                       -8.3247e-02,  6.8919e-02, -9.3894e-02, -3.8512e-02, -1.6826e-02,\n",
       "                       -7.5454e-02, -5.7127e-02, -7.0072e-02, -7.1726e-02, -3.2908e-02,\n",
       "                        7.5307e-02, -7.5873e-02, -6.4424e-02,  8.3349e-02, -4.7898e-02,\n",
       "                       -1.5665e-02,  6.8403e-02,  8.2435e-02, -8.8924e-02, -4.0928e-02,\n",
       "                        9.6695e-02,  5.1734e-02, -2.0524e-02,  2.5732e-02,  5.5288e-02,\n",
       "                       -4.6220e-03, -2.6337e-02,  3.5860e-02, -6.8184e-02,  8.4698e-03,\n",
       "                        2.6462e-02,  7.3722e-02, -2.2814e-02, -5.8806e-02, -5.6293e-02,\n",
       "                       -4.8926e-02,  6.6824e-02, -4.3384e-02,  5.2852e-03,  8.6940e-02,\n",
       "                       -2.9860e-02,  8.2980e-02, -8.9719e-02, -7.5280e-02, -3.0309e-02,\n",
       "                       -7.8989e-02,  8.3780e-02, -9.4103e-02, -8.7783e-02,  6.1991e-03,\n",
       "                       -4.9116e-02, -7.6697e-02,  4.7066e-02,  3.3420e-02, -1.0245e-03,\n",
       "                       -2.7101e-02,  3.1927e-02, -5.9668e-02,  1.9682e-02, -3.0590e-02,\n",
       "                       -9.2723e-03, -7.9688e-02,  9.3615e-02,  4.9679e-02,  9.2617e-03,\n",
       "                        5.2759e-02,  2.5570e-02, -3.4121e-02,  1.0737e-01],\n",
       "                      [ 8.5183e-02,  4.0946e-02,  9.6125e-02, -5.0334e-02, -3.7240e-02,\n",
       "                        1.6183e-02, -3.6578e-02,  4.1555e-02,  4.3730e-02,  6.2526e-02,\n",
       "                        8.6639e-02, -9.6284e-02,  3.7341e-02, -1.7327e-02,  9.4680e-02,\n",
       "                        6.4088e-02,  1.8637e-02,  7.5552e-03,  9.3541e-02, -6.0108e-02,\n",
       "                        7.4282e-02,  3.2062e-02, -5.3616e-02,  4.2524e-02,  6.8926e-02,\n",
       "                        3.2538e-02,  6.6840e-02,  1.3369e-04, -3.4249e-02, -1.4388e-02,\n",
       "                       -4.9689e-02,  9.0571e-02, -1.0852e-01,  1.0092e-01,  4.0953e-02,\n",
       "                        9.6760e-02,  5.1182e-03,  6.2154e-02, -1.0118e-02, -3.7100e-02,\n",
       "                       -4.4006e-02, -8.5831e-02,  2.1318e-02,  6.2597e-02, -1.0642e-02,\n",
       "                        4.3829e-02,  4.3141e-02,  6.7327e-02,  1.0201e-01, -1.0071e-01,\n",
       "                        2.2219e-03, -8.2042e-03,  7.5557e-02, -1.9962e-02, -5.8887e-02,\n",
       "                        4.3123e-02,  1.0128e-01, -2.9469e-02, -8.2541e-02, -6.3805e-02,\n",
       "                        9.9096e-02,  4.5819e-02,  3.1606e-02,  2.2889e-02, -2.4554e-02,\n",
       "                        1.5128e-02,  3.2185e-02,  6.6906e-02, -1.3197e-02, -4.2263e-02,\n",
       "                        4.1320e-02, -8.0096e-02,  8.6227e-02,  5.1326e-02, -2.1974e-02,\n",
       "                       -9.0085e-02,  2.5213e-02,  4.0116e-02,  7.9189e-02, -7.7958e-02,\n",
       "                       -8.9133e-03, -8.4532e-02, -1.9461e-02,  8.8652e-02],\n",
       "                      [ 7.4776e-03, -7.6775e-02, -4.6566e-02,  1.0717e-01,  4.2313e-02,\n",
       "                       -7.2416e-02, -3.6517e-02,  9.0656e-02,  1.0871e-01, -7.8489e-02,\n",
       "                        5.2212e-02,  8.8376e-02,  9.2447e-02, -4.5279e-02, -8.9062e-02,\n",
       "                       -1.5769e-02,  6.7271e-02, -3.5165e-02, -4.2458e-02,  9.8198e-02,\n",
       "                        5.8066e-02,  7.7679e-02,  3.7200e-02,  1.0380e-01,  6.5058e-02,\n",
       "                        7.6959e-02, -8.9007e-02,  1.0264e-01,  8.2963e-03,  7.1332e-02,\n",
       "                        5.8776e-02,  9.8627e-02,  2.3548e-02, -6.9517e-02,  7.5049e-02,\n",
       "                       -4.6007e-02, -2.4052e-03, -4.6130e-02, -9.4023e-02,  9.1814e-02,\n",
       "                        5.3004e-02, -9.9029e-02, -6.0543e-02, -8.8769e-03,  4.0520e-02,\n",
       "                        8.1122e-02, -1.0144e-01, -3.4057e-02,  6.0760e-02, -8.7515e-02,\n",
       "                        9.1064e-02,  2.4460e-03, -3.3452e-02,  4.3282e-02,  6.8299e-02,\n",
       "                       -2.0190e-02, -4.3615e-02, -6.6906e-02, -2.8233e-02,  5.8411e-02,\n",
       "                       -2.7437e-02, -6.6931e-02,  3.7783e-02, -5.3944e-02,  1.0714e-01,\n",
       "                       -1.4804e-02,  6.1235e-02,  5.6026e-02, -3.7729e-03,  3.8010e-02,\n",
       "                       -2.5371e-03,  1.6562e-02, -3.0523e-02, -2.4388e-02,  2.3437e-02,\n",
       "                       -1.9613e-02,  1.0616e-01, -2.8173e-02, -5.8274e-02, -6.1448e-02,\n",
       "                        2.6274e-02, -7.0881e-02,  7.6003e-02,  4.7961e-02],\n",
       "                      [-1.4838e-02,  1.9461e-02, -3.7006e-02,  4.6856e-02,  2.7434e-03,\n",
       "                       -8.7389e-03, -7.1765e-02,  7.3531e-04, -7.9098e-02, -7.3048e-02,\n",
       "                        4.7326e-02,  1.0647e-01,  1.7638e-02, -1.0339e-01, -9.2289e-02,\n",
       "                       -6.9117e-02,  1.0059e-02,  7.7558e-02, -3.0375e-02,  3.9401e-02,\n",
       "                       -1.0524e-01, -5.2170e-02,  5.7665e-02, -3.6997e-02,  9.8051e-02,\n",
       "                        1.0744e-01, -4.7998e-02, -3.8833e-02,  4.8011e-02, -5.6215e-02,\n",
       "                        6.0680e-02, -2.0466e-02,  4.6317e-02, -8.9304e-02,  1.8202e-02,\n",
       "                        2.7667e-02, -2.9132e-02, -9.9809e-02, -2.0045e-02,  9.4381e-02,\n",
       "                        9.8439e-03,  5.7562e-02, -5.0804e-02,  2.7741e-03, -7.3328e-02,\n",
       "                       -2.0860e-02, -7.6037e-02,  1.4103e-02,  8.9176e-02,  2.5887e-02,\n",
       "                       -7.0969e-02,  9.0980e-02, -3.2675e-02,  3.5035e-02,  5.6300e-02,\n",
       "                       -7.2780e-03, -3.0585e-02,  4.0204e-02,  9.3695e-02,  2.3649e-02,\n",
       "                       -6.5021e-02,  9.1500e-02, -1.3727e-03,  1.0767e-01,  7.5745e-02,\n",
       "                       -9.5607e-02, -5.8544e-03, -1.2652e-02,  4.9617e-02, -1.0155e-01,\n",
       "                        4.1545e-02, -8.0589e-02, -9.9300e-02,  4.2444e-02,  1.0846e-01,\n",
       "                       -6.2271e-02,  1.0469e-01, -1.0390e-01, -9.7226e-02,  1.0885e-01,\n",
       "                        7.9414e-02,  9.6198e-02, -5.5387e-02,  1.0516e-01],\n",
       "                      [-1.0262e-01,  3.6565e-02,  4.6331e-02, -9.7369e-02, -2.0603e-03,\n",
       "                        3.8740e-02, -1.3038e-02,  6.2590e-03,  8.9459e-02, -1.9888e-02,\n",
       "                       -7.2400e-02, -4.3411e-02,  2.5658e-02, -4.5482e-02,  2.2263e-02,\n",
       "                        4.1224e-02, -9.1505e-02,  5.4919e-02,  8.8382e-02,  8.0655e-03,\n",
       "                        3.0921e-03,  3.3724e-02, -6.4811e-02,  9.2307e-02, -2.2898e-02,\n",
       "                       -3.9931e-02,  2.3447e-02, -9.4078e-02,  9.9495e-02, -9.0226e-02,\n",
       "                        3.5269e-02, -6.1806e-02, -8.4449e-03, -6.0450e-02,  1.0026e-01,\n",
       "                       -8.8112e-02, -4.7145e-02,  1.3285e-02, -9.1045e-02,  4.7457e-02,\n",
       "                       -1.7129e-02, -3.3492e-02,  3.0392e-02, -3.4826e-02,  8.6752e-02,\n",
       "                        4.4658e-03,  1.4885e-02, -6.6298e-02, -5.2843e-02, -5.1061e-03,\n",
       "                       -8.2972e-02, -1.0769e-01, -9.0801e-02, -1.9454e-03, -1.3892e-02,\n",
       "                        8.3482e-02, -7.5861e-02,  6.5185e-02,  2.4558e-02, -4.2574e-02,\n",
       "                        9.7212e-02, -8.2387e-02,  8.8351e-02, -4.8597e-02, -1.0888e-01,\n",
       "                        7.1817e-02,  2.6067e-02, -3.2932e-02,  9.6718e-02,  9.4977e-02,\n",
       "                        6.3211e-02,  1.0853e-01, -2.9133e-02, -1.5664e-03,  1.0479e-01,\n",
       "                        6.3738e-02, -4.0859e-03,  7.1537e-02, -7.5081e-02, -2.8500e-02,\n",
       "                        2.0952e-03, -1.0699e-01, -6.6680e-02,  7.9732e-02]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([-0.0440, -0.0401,  0.0500, -0.0199, -0.0542, -0.0948,  0.0837,  0.0933,\n",
       "                       0.0823,  0.0620]))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading Model for Inference\n",
    "\n",
    "Save/Load state_dict (Recommended)\n",
    "\n",
    "### Save:\n",
    "`torch.save(model.state_dict(), PATH)`\n",
    "\n",
    "### Load:\n",
    "``model = ModelClass(*args, **kwargs)``\n",
    "\n",
    "``model.load_state_dict(torch.load(PATH))``\n",
    "\n",
    "`model.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../../../MEGA/DatabaseLocal/myNet.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When saving a model for inference**, it is only necessary to save the trained model’s learned parameters. Saving the model’s state_dict with the torch.save() function will give you the most flexibility for restoring the model later, which is why it is the recommended method for saving models.\n",
    "\n",
    "A common PyTorch convention is to save models using either a .pt or .pth file extension.\n",
    "\n",
    "Remember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    "\n",
    "#### NOTE\n",
    "\n",
    "Notice that the load_state_dict() function takes a dictionary object, NOT a path to a saved object. This means that you must deserialize the saved state_dict before you pass it to the load_state_dict() function. For example, you CANNOT load using model.load_state_dict(PATH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelClass()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Entire Model\n",
    "#### Save:\n",
    "\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load:\n",
    "\n",
    "#### Model class must be defined somewhere\n",
    "\n",
    "model = torch.load(PATH)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Python’s pickle module. **The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved**. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors.\n",
    "\n",
    "A common PyTorch convention is to save models using either a .pt or .pth file extension.\n",
    "\n",
    "Remember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading a General Checkpoint for Inference and/or Resuming Training\n",
    "\n",
    "#### Save:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = ModelClass()\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
