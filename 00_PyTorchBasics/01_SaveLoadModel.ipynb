{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING AND LOADING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document provides solutions to a variety of use cases regarding the saving and loading of PyTorch models. Feel free to read the whole document, or just skip to the code you need for a desired use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to saving and loading models, there are three core functions to be familiar with:\n",
    "\n",
    "- `torch.save`: Saves a serialized object to disk. This function uses Python’s `pickle` utility for serialization. Models, tensors, and dictionaries of all kinds of objects can be saved using this function.\n",
    "- `torch.load`: Uses `pickle`’s unpickling facilities to deserialize pickled object files to memory. This function also facilitates the device to load the data into (see Saving & Loading Model Across Devices).\n",
    "- `torch.nn.Module.load_state_dict`: Loads a model’s parameter dictionary using a deserialized state_dict. For more information on state_dict, see What is a state_dict?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "- What is a state_dict?\n",
    "- Saving & Loading Model for Inference\n",
    "- Saving & Loading a General Checkpoint\n",
    "- Saving Multiple Models in One File\n",
    "- Warmstarting Model Using Parameters from a Different Model\n",
    "- Saving & Loading Model Across Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a state_dict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the learnable parameters (i.e. weights and biases) of an `torch.nn.Module` model are contained in the model’s parameters (accessed with `model.parameters()`). A `state_dict` is simply a Python dictionary object that maps each layer to its parameter tensor. Note that only layers with learnable parameters (convolutional layers, linear layers, etc.) and registered buffers (batchnorm’s running_mean) have entries in the model’s state_dict. Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizer’s state, as well as the hyperparameters used.\n",
    "\n",
    "Because `state_dict` objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at the `state_dict` from the simple model used in the Training a classifier tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140158265378928, 140158265379720, 140158265378568, 140158265378712, 140158265378496, 140158265378280, 140158265378064, 140158265377848, 140158265378856, 140158265379216]}]\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-4.2429e-02,  5.9782e-02,  5.0412e-02,  1.8451e-02,  2.6615e-02],\n",
       "                        [ 9.4491e-02, -7.4326e-02, -3.4779e-03,  9.1112e-02, -5.9225e-02],\n",
       "                        [ 9.0978e-02, -6.1702e-03,  5.4920e-02, -5.3032e-03,  6.6603e-02],\n",
       "                        [-4.8112e-03, -3.5489e-02, -1.1200e-01,  3.2576e-02, -9.5213e-02],\n",
       "                        [ 1.0924e-01,  6.0533e-02,  1.0165e-01, -8.4772e-03, -4.2743e-02]],\n",
       "              \n",
       "                       [[-3.8417e-02, -4.2031e-02, -6.0666e-03, -8.6070e-02, -9.4199e-02],\n",
       "                        [ 1.1180e-01,  1.1926e-02, -7.3397e-02, -9.8471e-02,  3.5933e-02],\n",
       "                        [ 5.8302e-02, -7.2425e-02, -9.3167e-02, -7.1973e-02, -5.0978e-02],\n",
       "                        [ 1.1384e-01,  7.0082e-02, -6.8690e-02,  6.5220e-02,  8.0614e-02],\n",
       "                        [ 7.5960e-02,  5.6229e-02, -9.1138e-03,  1.1053e-01,  2.2933e-02]],\n",
       "              \n",
       "                       [[-2.4320e-02, -4.9308e-02, -3.6248e-03, -8.1694e-02,  1.7029e-02],\n",
       "                        [-1.0519e-01, -9.4996e-02,  6.4813e-02, -5.9291e-02, -1.0985e-01],\n",
       "                        [ 1.3244e-02,  1.0544e-02, -7.6158e-02,  9.0870e-02, -4.7966e-02],\n",
       "                        [ 8.0236e-02, -1.0973e-02,  1.0202e-01, -1.5291e-02, -2.2115e-02],\n",
       "                        [-1.0825e-01,  7.5112e-02, -4.0201e-02, -7.7383e-03, -1.0128e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8780e-02, -8.3505e-02,  7.7015e-02,  1.0643e-01, -7.5677e-02],\n",
       "                        [-1.1520e-01, -1.5740e-02,  7.8285e-02, -2.6808e-02,  6.8368e-02],\n",
       "                        [-4.6505e-02, -2.1514e-02,  8.4399e-02, -7.7968e-02,  7.3993e-02],\n",
       "                        [-6.4524e-02,  9.2197e-02,  5.0541e-03,  9.1544e-02,  3.4729e-02],\n",
       "                        [ 9.2364e-02,  1.2491e-02,  5.9515e-02,  2.5371e-02, -3.4078e-02]],\n",
       "              \n",
       "                       [[-1.4895e-02,  2.2827e-02,  8.9296e-02,  3.4247e-02,  9.5220e-02],\n",
       "                        [ 6.6453e-02,  9.4453e-03, -7.3434e-02, -1.1492e-01,  5.3644e-02],\n",
       "                        [ 7.4315e-02,  3.1837e-02, -1.9467e-02, -4.1085e-02,  4.5756e-02],\n",
       "                        [-7.9477e-02, -8.4539e-02, -1.1127e-02, -3.8296e-02,  4.6908e-02],\n",
       "                        [-7.9505e-02,  7.0903e-02, -4.8205e-02, -7.5197e-03,  2.3434e-02]],\n",
       "              \n",
       "                       [[ 4.7323e-02, -9.8214e-02, -4.6481e-02,  6.3947e-02, -6.3759e-02],\n",
       "                        [-1.9713e-02, -3.3097e-02, -8.7818e-02, -7.2707e-02,  5.0679e-02],\n",
       "                        [-8.6096e-03,  9.7522e-02, -3.1459e-02,  4.2982e-02, -4.8566e-02],\n",
       "                        [ 3.7681e-02,  1.1002e-02, -9.2371e-02,  1.0929e-01, -5.2554e-02],\n",
       "                        [ 3.0479e-03, -5.2237e-02,  6.1766e-02, -7.0012e-02, -1.2179e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.9369e-02, -1.2329e-02,  2.8160e-02,  9.4994e-02,  6.0712e-02],\n",
       "                        [-2.7337e-02, -8.1060e-02, -4.0779e-02,  1.0450e-01,  4.0803e-02],\n",
       "                        [-4.0715e-02,  1.0231e-01,  9.2134e-02, -6.1209e-02,  8.2879e-02],\n",
       "                        [-7.4110e-03,  2.7350e-02,  7.7516e-03,  3.0425e-02,  6.6403e-02],\n",
       "                        [ 2.3186e-02,  4.0109e-02,  2.9713e-02,  9.8136e-02,  2.5750e-02]],\n",
       "              \n",
       "                       [[-2.3747e-02, -7.1779e-02,  6.5895e-02,  8.4124e-02, -3.2589e-02],\n",
       "                        [-6.7041e-02,  5.4523e-02, -2.9895e-02, -6.0215e-02,  2.1613e-02],\n",
       "                        [-4.2101e-02,  5.0055e-03, -2.8076e-03, -6.2451e-02, -4.4510e-02],\n",
       "                        [-3.8420e-02, -7.9358e-02,  4.4689e-03, -1.9898e-02, -8.0235e-02],\n",
       "                        [-1.0268e-02, -8.9465e-02,  3.3407e-02, -2.4458e-02, -7.2902e-02]],\n",
       "              \n",
       "                       [[ 5.3588e-02, -7.0957e-02,  1.0928e-01, -9.3210e-02, -6.5286e-02],\n",
       "                        [ 3.5080e-02,  9.7790e-02, -9.4205e-03,  4.8841e-02, -2.0904e-02],\n",
       "                        [ 6.4626e-02, -4.5236e-02,  8.8040e-02,  1.0240e-01,  5.4349e-02],\n",
       "                        [-7.8031e-02,  9.1202e-03,  1.4906e-02, -5.4591e-02, -1.0157e-01],\n",
       "                        [-1.0229e-04,  6.4238e-02,  9.3008e-02, -1.0205e-01,  7.9854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1681e-02, -4.9958e-02, -1.7236e-02, -4.9954e-02,  1.7172e-02],\n",
       "                        [ 7.5824e-02, -1.0864e-01,  8.2735e-02,  8.6961e-02,  6.9526e-02],\n",
       "                        [ 1.0614e-01,  9.5462e-02,  1.0412e-01, -3.2434e-02, -1.1192e-01],\n",
       "                        [ 2.5601e-02, -9.3257e-02,  6.5255e-02, -2.4301e-03, -7.0227e-02],\n",
       "                        [ 1.0256e-02, -1.2032e-02, -1.0505e-01,  7.3158e-02,  4.9103e-03]],\n",
       "              \n",
       "                       [[ 1.2934e-02, -1.3131e-02, -4.1096e-02,  1.1720e-02, -1.3060e-02],\n",
       "                        [ 7.5175e-02,  7.3263e-02,  3.9987e-02,  3.2310e-02,  2.5193e-02],\n",
       "                        [ 1.1094e-02, -6.0024e-02, -1.8475e-02, -6.4218e-02,  2.7178e-02],\n",
       "                        [ 8.1338e-03, -3.1308e-02, -2.7661e-02,  1.1163e-01, -7.7628e-03],\n",
       "                        [-7.9240e-02, -9.0158e-02,  3.8118e-02, -1.0226e-01,  2.6709e-02]],\n",
       "              \n",
       "                       [[-4.4437e-02,  4.9162e-03, -3.9904e-02,  8.2971e-03, -7.2043e-02],\n",
       "                        [ 2.8226e-02, -7.3940e-02,  4.5811e-03,  7.3533e-02, -5.4916e-02],\n",
       "                        [ 6.0247e-02,  9.6502e-02, -2.4708e-02,  1.1129e-01,  3.2652e-03],\n",
       "                        [-4.6975e-02,  2.6245e-02, -1.0181e-02, -7.0730e-02,  9.6919e-02],\n",
       "                        [ 1.7843e-02, -3.7205e-02,  9.3261e-02,  2.3485e-02,  1.5058e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.5208e-03, -3.4466e-02, -1.3831e-02, -2.0223e-02,  1.1130e-01],\n",
       "                        [ 1.1186e-01, -5.6172e-02,  4.7975e-02, -6.6432e-03,  1.7578e-02],\n",
       "                        [ 8.1369e-02, -7.6838e-02, -2.5363e-02, -3.5994e-03, -1.0891e-01],\n",
       "                        [ 6.1897e-02, -5.5562e-02, -8.9708e-02, -7.6868e-02,  4.1689e-02],\n",
       "                        [ 8.6872e-02,  2.8315e-02, -7.5275e-02, -1.5553e-02,  6.6032e-02]],\n",
       "              \n",
       "                       [[-1.0454e-01, -1.3052e-02, -8.3739e-03,  9.2912e-02, -3.0130e-03],\n",
       "                        [-4.5011e-02, -8.2020e-02,  2.1301e-02,  5.2632e-02, -9.0573e-02],\n",
       "                        [-1.0774e-01,  6.8576e-02,  2.9562e-02,  1.0357e-01, -1.6352e-02],\n",
       "                        [-3.3365e-02,  1.5001e-02, -6.6493e-02, -3.2558e-02, -4.2866e-03],\n",
       "                        [-4.5368e-02, -7.6936e-02, -1.0479e-01, -2.9103e-02, -4.8544e-02]],\n",
       "              \n",
       "                       [[-8.9256e-02, -3.9342e-02, -6.0645e-02,  9.1921e-02, -5.2337e-02],\n",
       "                        [-3.3242e-02, -1.0674e-01,  1.4026e-02, -4.9085e-02,  7.5249e-03],\n",
       "                        [-7.0112e-02,  2.0839e-02, -7.0097e-02, -6.0625e-02, -9.0018e-02],\n",
       "                        [ 2.0015e-02,  7.1395e-02, -1.0750e-01, -1.1236e-01, -6.6532e-02],\n",
       "                        [-8.0603e-02, -6.6037e-02, -5.3370e-02, -7.1917e-02, -5.2678e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.2373e-02, -4.9347e-02,  5.2471e-02,  9.6582e-02,  6.9969e-02],\n",
       "                        [ 4.4152e-03,  8.3355e-02, -1.0405e-01,  8.5749e-02,  2.5328e-02],\n",
       "                        [-2.0961e-02,  4.4815e-02,  3.5109e-02,  8.3556e-02,  7.4354e-02],\n",
       "                        [-2.2184e-02,  1.1048e-01, -1.0564e-01, -3.1903e-02,  1.0527e-01],\n",
       "                        [-3.2341e-02,  1.0561e-02, -1.1442e-01, -7.3941e-02,  7.0939e-02]],\n",
       "              \n",
       "                       [[-8.5514e-02,  1.1338e-01,  9.4044e-02, -2.9586e-02,  5.2003e-02],\n",
       "                        [ 5.5736e-02,  7.5316e-02,  2.2604e-02,  1.0894e-02, -2.6153e-02],\n",
       "                        [-3.8441e-02, -3.8061e-02, -3.1127e-02,  7.7792e-02, -4.1495e-02],\n",
       "                        [ 1.2783e-02, -1.8801e-02,  1.4275e-02, -7.4402e-02, -4.8430e-02],\n",
       "                        [-3.7318e-02, -1.0363e-01,  3.5339e-02,  5.4911e-02,  5.9715e-02]],\n",
       "              \n",
       "                       [[ 4.6668e-03, -1.1059e-01,  7.4382e-02, -9.5337e-02,  1.1128e-01],\n",
       "                        [-4.6391e-02,  9.5224e-02,  1.0901e-01, -3.8802e-02,  2.0669e-02],\n",
       "                        [ 2.8923e-02,  1.0554e-01, -2.6645e-02,  6.6270e-02, -3.8419e-02],\n",
       "                        [ 8.5718e-02,  1.0872e-01,  1.0907e-03, -1.1357e-01, -1.0045e-01],\n",
       "                        [ 5.3842e-02,  1.0947e-01, -4.4687e-02,  5.2830e-02, -2.5560e-02]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 0.0782,  0.0275,  0.0815, -0.0626, -0.0504, -0.0356])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-5.5133e-02,  4.3238e-02,  7.3850e-02,  7.1774e-02,  7.1388e-02],\n",
       "                        [-3.6299e-05, -3.2853e-02, -3.8296e-02, -6.2129e-03, -6.6848e-02],\n",
       "                        [-2.4534e-02, -5.3760e-02,  1.1990e-03, -1.6503e-02,  1.2541e-02],\n",
       "                        [-4.6955e-02, -3.8786e-02, -2.8691e-02, -7.0752e-02, -6.7493e-02],\n",
       "                        [-8.8680e-03, -3.1834e-02, -5.8233e-02,  6.4747e-02, -2.7032e-02]],\n",
       "              \n",
       "                       [[-3.0338e-02,  1.7981e-03, -5.4490e-02, -1.6039e-02, -4.6141e-02],\n",
       "                        [ 7.3058e-02, -3.9229e-02, -9.4347e-05,  3.4030e-02,  5.9514e-02],\n",
       "                        [-3.3095e-02,  6.1230e-02, -5.5556e-02,  1.2286e-02,  6.4699e-02],\n",
       "                        [-4.3391e-02,  7.4064e-02, -3.0616e-02, -8.9456e-03, -5.9760e-02],\n",
       "                        [-1.3970e-02, -2.3128e-02,  6.6400e-02,  3.9460e-02,  6.3138e-02]],\n",
       "              \n",
       "                       [[ 5.0683e-02, -3.1545e-02,  6.3776e-03,  3.2776e-03,  6.0021e-02],\n",
       "                        [-4.5702e-02,  4.2106e-02, -2.6393e-02,  2.0320e-02, -7.7852e-02],\n",
       "                        [ 6.6573e-02,  2.7784e-02, -5.7352e-03, -4.8377e-02, -2.1262e-02],\n",
       "                        [-4.9830e-02, -4.3434e-02,  5.0619e-03, -2.7050e-02,  7.6313e-02],\n",
       "                        [ 7.3801e-02, -7.0821e-03, -1.4484e-02, -3.3426e-02,  4.6052e-02]],\n",
       "              \n",
       "                       [[ 4.7061e-02, -9.7626e-03, -4.9606e-02, -3.3703e-02, -6.2266e-03],\n",
       "                        [-7.0961e-02,  8.2462e-03,  5.1600e-02,  5.5899e-02, -8.5081e-03],\n",
       "                        [-3.0684e-02,  2.2099e-02,  7.3048e-02, -1.3977e-02,  4.2936e-02],\n",
       "                        [-6.3315e-02, -1.6428e-02,  5.7901e-02, -5.6978e-02,  6.8253e-02],\n",
       "                        [-3.8068e-02,  2.6787e-02, -5.2648e-02, -2.3467e-02,  6.3835e-02]],\n",
       "              \n",
       "                       [[-1.8747e-02, -6.3107e-02,  4.7643e-02, -1.1308e-02, -3.6523e-03],\n",
       "                        [ 6.9125e-02,  7.6448e-02, -6.3153e-02,  1.3614e-02,  5.4191e-02],\n",
       "                        [-5.9019e-02,  5.4400e-02, -5.6517e-02,  4.9688e-03, -7.7198e-02],\n",
       "                        [-3.3811e-02, -2.8671e-02, -8.9167e-03, -8.0282e-02, -9.2044e-03],\n",
       "                        [ 4.4453e-03,  4.2536e-02, -7.8811e-02,  6.2635e-02,  4.1038e-02]],\n",
       "              \n",
       "                       [[ 3.1405e-02, -4.8038e-03, -4.2800e-03,  4.9774e-02, -2.5587e-02],\n",
       "                        [-2.4989e-02, -1.1075e-02, -3.2887e-02, -3.6721e-03, -1.5204e-02],\n",
       "                        [-2.7118e-02, -5.1964e-02,  6.6566e-02,  4.8076e-02, -6.5895e-02],\n",
       "                        [ 2.5573e-02, -5.2047e-02, -8.0228e-02,  3.6845e-03,  4.1099e-02],\n",
       "                        [-1.7538e-02, -7.1747e-02,  7.2290e-02, -1.3422e-02, -4.5331e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.4246e-03, -2.2556e-02,  9.8500e-03,  1.0922e-02,  3.2681e-02],\n",
       "                        [-3.5849e-02,  2.3838e-02,  6.1474e-02,  8.5619e-03,  2.0905e-02],\n",
       "                        [ 6.2405e-02,  3.3110e-02, -8.2316e-03, -6.3851e-02, -1.0476e-02],\n",
       "                        [ 7.5338e-02, -3.9385e-03, -4.7596e-03,  6.9785e-02, -3.2814e-02],\n",
       "                        [-7.7349e-02, -7.9371e-02, -5.3393e-02,  4.1797e-02,  4.0901e-03]],\n",
       "              \n",
       "                       [[-7.3187e-02, -6.9179e-02,  2.6229e-02, -6.7504e-02, -2.8676e-03],\n",
       "                        [ 8.1437e-02,  5.7688e-02,  5.4202e-02,  6.2182e-02,  7.5121e-02],\n",
       "                        [-7.7428e-02,  6.1737e-02, -7.2171e-03,  5.5608e-02, -3.4591e-02],\n",
       "                        [-4.4617e-02,  1.6359e-02, -5.6431e-02, -3.5481e-02, -5.3829e-02],\n",
       "                        [ 1.6267e-02, -2.1435e-02,  8.1273e-02, -4.0933e-03, -4.1449e-02]],\n",
       "              \n",
       "                       [[ 4.4455e-02, -2.4403e-03, -4.2739e-02,  7.5660e-02, -6.4785e-02],\n",
       "                        [ 9.3158e-03,  1.9816e-02,  1.2759e-02,  4.1128e-02,  5.1681e-02],\n",
       "                        [-1.6669e-02,  5.4477e-02, -6.5254e-02, -3.0400e-02,  5.0290e-02],\n",
       "                        [-1.7183e-02, -3.9660e-02,  5.5972e-02, -7.1685e-02,  3.0120e-02],\n",
       "                        [-9.7991e-03,  7.7679e-02,  7.6982e-02, -1.1334e-02,  5.3359e-02]],\n",
       "              \n",
       "                       [[-3.9358e-02,  2.9648e-02,  6.4080e-02, -8.3456e-03, -3.3744e-02],\n",
       "                        [-1.8436e-02, -5.7907e-02, -2.7171e-02, -7.6334e-02,  1.5143e-02],\n",
       "                        [-2.0153e-02,  4.0531e-02,  2.6331e-02,  4.1412e-03, -2.6064e-02],\n",
       "                        [ 6.3147e-02, -2.3055e-02,  5.6749e-02,  1.4041e-02,  8.3498e-03],\n",
       "                        [-1.2044e-02, -8.7232e-03,  7.4290e-02, -2.7087e-02,  1.4291e-02]],\n",
       "              \n",
       "                       [[-9.1162e-03,  7.4078e-02, -3.9598e-03, -2.7090e-02,  1.2119e-02],\n",
       "                        [-4.9912e-02, -5.6942e-02,  3.3226e-02,  3.9189e-02,  5.8024e-02],\n",
       "                        [ 1.8315e-02, -6.6264e-03,  4.8345e-02, -1.0389e-02,  6.8944e-02],\n",
       "                        [ 2.6513e-02, -5.4864e-02, -2.2445e-02,  5.4375e-02,  6.1282e-02],\n",
       "                        [ 7.7657e-02,  4.0961e-02,  3.5610e-02,  2.3946e-03,  4.8760e-02]],\n",
       "              \n",
       "                       [[-6.0985e-02, -5.9102e-02,  1.0257e-02,  2.0136e-02, -4.3774e-02],\n",
       "                        [ 5.0338e-02, -7.2010e-02, -1.9235e-02, -6.0733e-02,  1.5743e-02],\n",
       "                        [ 1.9131e-02,  8.0614e-02, -1.7153e-02,  6.3118e-02, -5.7101e-02],\n",
       "                        [ 1.5447e-02,  3.3349e-02, -7.5214e-03,  5.4555e-02, -1.9250e-02],\n",
       "                        [ 4.9541e-02,  6.4489e-02,  1.8561e-02,  7.9962e-02, -4.1700e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.6216e-02, -4.2433e-02, -1.3810e-02,  2.6907e-02, -3.4129e-02],\n",
       "                        [-1.3466e-03,  1.5544e-02,  7.4747e-02, -7.8899e-02, -4.4189e-02],\n",
       "                        [ 9.3912e-03, -1.8499e-02, -1.1225e-03,  5.9927e-02,  4.0895e-02],\n",
       "                        [ 2.0763e-02,  7.5925e-02,  4.1575e-02, -7.9141e-02, -9.5501e-03],\n",
       "                        [-1.2969e-03,  5.2738e-02, -6.9162e-04, -1.1244e-02, -6.4805e-02]],\n",
       "              \n",
       "                       [[ 5.0203e-02,  5.5624e-03,  4.9862e-03,  4.9466e-02, -4.7666e-02],\n",
       "                        [-1.6786e-02,  2.4187e-02,  2.5190e-02,  3.8332e-02,  2.0499e-02],\n",
       "                        [ 2.1468e-02,  4.9010e-03, -5.9540e-02, -4.7220e-02,  2.2155e-03],\n",
       "                        [-2.0919e-02,  6.7845e-02,  4.2661e-02, -7.2285e-02, -3.3841e-02],\n",
       "                        [-2.6249e-02, -4.5176e-02, -1.1295e-02, -2.2914e-02,  1.9513e-02]],\n",
       "              \n",
       "                       [[ 1.6963e-02, -3.8743e-02,  6.0048e-02,  4.0164e-02,  2.9233e-02],\n",
       "                        [ 2.6586e-02, -6.8151e-02, -7.9798e-02,  4.2077e-02,  6.3009e-02],\n",
       "                        [-8.0805e-02, -7.5161e-02,  6.8957e-02,  6.9772e-02, -1.9147e-02],\n",
       "                        [ 5.8036e-02, -6.8139e-02,  5.4269e-02,  4.8650e-02, -4.2169e-02],\n",
       "                        [-7.4370e-02,  2.2509e-02,  2.8118e-02,  4.0955e-02,  7.2247e-03]],\n",
       "              \n",
       "                       [[ 5.4903e-02, -7.4334e-02, -1.8442e-02, -3.4933e-02, -1.6930e-02],\n",
       "                        [-6.2694e-02, -5.7089e-02, -1.9658e-02, -6.4948e-02, -7.9974e-02],\n",
       "                        [-4.6600e-02,  2.2730e-02, -7.9853e-02,  4.4225e-02,  2.1118e-02],\n",
       "                        [-1.2357e-02,  5.4468e-02, -7.2839e-02,  1.2447e-02,  3.6890e-02],\n",
       "                        [-3.6258e-02, -4.8890e-02,  5.3034e-02,  3.2737e-02, -1.5074e-02]],\n",
       "              \n",
       "                       [[ 7.3659e-02,  9.4790e-03,  6.8651e-02,  7.5660e-02, -3.5046e-02],\n",
       "                        [ 2.7114e-02,  2.4224e-02, -8.0627e-02, -6.6826e-02,  4.9329e-02],\n",
       "                        [ 3.9067e-02, -4.1673e-02,  5.2144e-03, -2.3608e-02, -1.9809e-02],\n",
       "                        [-2.1843e-02,  6.4507e-02,  5.4705e-02,  4.2675e-02, -1.9701e-02],\n",
       "                        [-2.2481e-02, -4.7802e-02, -3.6855e-02, -1.2886e-02, -5.1058e-03]],\n",
       "              \n",
       "                       [[-5.4208e-02, -6.2237e-02, -2.7203e-02, -1.5838e-02, -2.5362e-02],\n",
       "                        [ 2.0305e-02,  7.0920e-02, -2.8770e-02,  3.4396e-02, -6.3688e-02],\n",
       "                        [ 3.3917e-02, -5.8769e-02,  1.6587e-02,  9.3191e-03, -6.7587e-02],\n",
       "                        [-7.6548e-02, -8.1473e-02,  8.0337e-02,  3.1825e-02,  2.0485e-02],\n",
       "                        [-6.1384e-02, -6.6972e-02, -2.8867e-02,  6.3724e-02,  7.5210e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.5473e-02,  5.8120e-02, -1.3816e-02,  4.2095e-02,  3.2204e-02],\n",
       "                        [-5.9797e-02, -2.1238e-02,  1.1780e-02, -2.9236e-02, -2.8903e-02],\n",
       "                        [ 6.7974e-02,  1.8833e-02,  3.9798e-03, -5.6984e-04, -3.9575e-02],\n",
       "                        [-1.0570e-02, -4.1095e-02,  7.1874e-02, -2.2535e-02, -4.6846e-02],\n",
       "                        [-6.6738e-02,  5.4376e-02,  1.4218e-02, -2.5497e-02, -6.4238e-02]],\n",
       "              \n",
       "                       [[-1.0932e-02,  4.1034e-02,  1.2649e-02, -7.8326e-02,  6.2943e-02],\n",
       "                        [-3.1214e-02, -9.8688e-03, -8.4297e-03,  3.1650e-02, -2.5266e-02],\n",
       "                        [-1.8232e-02, -1.0387e-02, -4.1307e-02, -9.4506e-03,  8.4136e-03],\n",
       "                        [ 7.1775e-02,  2.9175e-03,  4.4474e-02, -2.7666e-02, -2.0675e-02],\n",
       "                        [ 8.0074e-02, -1.5624e-02,  2.2444e-02, -4.9967e-02, -2.2898e-02]],\n",
       "              \n",
       "                       [[ 7.1685e-02, -3.9375e-02, -4.7338e-02,  8.7686e-03,  7.7136e-03],\n",
       "                        [-2.3219e-02,  1.2974e-02, -2.7651e-02, -6.6665e-02,  2.6239e-02],\n",
       "                        [-1.4170e-02, -6.0517e-02,  7.6884e-02, -7.5352e-02,  7.2398e-02],\n",
       "                        [-3.6604e-02,  4.9228e-02,  7.0770e-02, -2.4551e-02,  1.9105e-02],\n",
       "                        [ 5.0969e-02, -3.8888e-02, -8.1138e-03, -4.9505e-02, -2.3793e-02]],\n",
       "              \n",
       "                       [[ 1.4974e-02,  1.3083e-02,  5.9835e-03,  1.4152e-02,  4.4549e-02],\n",
       "                        [ 7.0763e-02,  2.4631e-02, -8.8895e-03, -7.5770e-02, -4.9759e-02],\n",
       "                        [ 4.5329e-02,  5.3519e-02, -5.7611e-02,  5.4204e-02,  2.7329e-02],\n",
       "                        [ 2.9531e-02,  1.0165e-03,  3.7400e-02,  2.8234e-02, -5.0140e-02],\n",
       "                        [ 2.8320e-02, -2.3465e-03, -2.5286e-02, -4.9387e-02,  8.8794e-03]],\n",
       "              \n",
       "                       [[ 1.4207e-02,  7.4436e-02,  6.0590e-02,  6.1283e-02, -5.7486e-02],\n",
       "                        [-3.0219e-02,  4.6649e-02, -5.7181e-02,  3.1861e-02,  7.0267e-02],\n",
       "                        [ 2.5710e-02,  5.0485e-03, -1.7998e-02,  5.6930e-02,  3.0799e-02],\n",
       "                        [-3.8940e-02, -7.6323e-02, -6.4222e-02,  2.3677e-02,  7.4613e-02],\n",
       "                        [ 1.4580e-02,  4.8274e-02,  4.9590e-02, -1.4673e-02, -7.9749e-02]],\n",
       "              \n",
       "                       [[ 8.1371e-02,  3.9951e-03,  2.8332e-02, -5.3778e-02,  1.4762e-02],\n",
       "                        [-6.8080e-02, -3.0987e-02,  5.8673e-02,  4.7556e-02,  6.6164e-02],\n",
       "                        [-5.9708e-02,  5.9000e-02, -1.5673e-02,  8.0153e-02, -5.3321e-02],\n",
       "                        [-4.0409e-02, -6.3900e-02, -6.6408e-03,  7.8167e-02, -3.8149e-02],\n",
       "                        [-4.2514e-02,  4.4107e-02,  4.2706e-02,  8.0443e-03,  1.8108e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6459e-02,  1.8347e-02, -6.1956e-02,  1.3374e-03, -5.2828e-02],\n",
       "                        [-6.9478e-02, -4.8295e-02, -4.5126e-02,  5.2183e-02,  6.0981e-02],\n",
       "                        [ 7.5012e-02, -2.1149e-02, -3.3584e-03, -2.9584e-02,  4.4095e-02],\n",
       "                        [-2.2707e-02, -6.3026e-02,  6.6395e-02, -4.3891e-02,  6.0101e-02],\n",
       "                        [ 6.7104e-02, -7.5697e-02,  7.1430e-02,  4.2984e-02,  2.1891e-02]],\n",
       "              \n",
       "                       [[-2.6108e-02,  7.4763e-02, -1.5023e-02,  4.5013e-02, -5.8995e-02],\n",
       "                        [-7.9831e-02, -6.0927e-02,  5.3937e-02, -3.5140e-02,  7.3868e-02],\n",
       "                        [ 2.6278e-02, -5.1556e-03,  4.1280e-02,  2.0605e-02, -7.6181e-02],\n",
       "                        [ 2.7862e-02,  3.4969e-02, -2.1035e-02, -8.0410e-03, -5.7576e-02],\n",
       "                        [-5.0346e-02,  5.2273e-02, -4.0297e-02,  6.7837e-02,  5.0490e-02]],\n",
       "              \n",
       "                       [[-5.0734e-02,  6.4859e-02,  5.2105e-02,  4.5578e-02,  6.3531e-02],\n",
       "                        [-1.2247e-02, -7.7229e-02,  1.4273e-02,  2.4456e-02, -7.0230e-02],\n",
       "                        [ 6.7554e-02,  6.0062e-02, -6.2539e-02,  1.9888e-02, -1.3899e-02],\n",
       "                        [-4.4886e-02, -5.9719e-03, -7.6984e-02,  3.1400e-02,  6.4328e-02],\n",
       "                        [-2.4605e-02, -1.6429e-03, -7.4755e-02,  8.1624e-02, -7.9544e-02]],\n",
       "              \n",
       "                       [[ 5.0792e-02,  5.9057e-02,  6.3768e-02,  2.7768e-03, -2.6541e-02],\n",
       "                        [ 2.0979e-03, -5.3493e-02,  2.9543e-02,  7.5499e-02, -5.6840e-02],\n",
       "                        [ 5.3844e-02,  4.8062e-02, -4.2387e-02,  1.9440e-02,  1.6486e-02],\n",
       "                        [-3.1392e-02, -6.0099e-02,  1.5479e-02, -5.9712e-02,  3.8105e-03],\n",
       "                        [ 3.7352e-02, -1.9675e-02, -4.2296e-02,  6.9326e-02,  4.4193e-02]],\n",
       "              \n",
       "                       [[ 3.7985e-02, -5.0552e-02, -3.5243e-02,  3.3788e-02,  1.7630e-02],\n",
       "                        [ 8.7487e-03, -8.3235e-03, -7.6125e-02,  7.3730e-02, -9.4408e-03],\n",
       "                        [ 7.4990e-02, -3.6171e-02, -4.2379e-03, -6.7538e-02, -4.7439e-03],\n",
       "                        [-9.3947e-03, -1.5293e-02,  7.3626e-02,  5.6141e-02,  1.0536e-02],\n",
       "                        [-5.4379e-02, -1.4531e-02,  5.1212e-02, -6.3878e-02, -1.1068e-02]],\n",
       "              \n",
       "                       [[-5.5610e-02, -2.5175e-02,  1.7668e-02, -4.6828e-02, -3.3399e-02],\n",
       "                        [-2.5489e-02, -4.6526e-02,  1.5075e-02,  4.8373e-02,  1.4534e-02],\n",
       "                        [ 5.8605e-02, -1.8106e-02, -5.6920e-02,  2.9478e-02, -7.1433e-02],\n",
       "                        [-6.1955e-02, -6.5671e-03, -1.3578e-02,  2.6809e-02, -5.2249e-02],\n",
       "                        [-2.6263e-02, -2.6108e-02, -4.5023e-03,  5.8935e-03,  7.0565e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3022e-02, -5.5440e-02,  4.8257e-02, -4.4913e-02,  1.9548e-02],\n",
       "                        [ 3.0551e-02,  6.4687e-02, -5.4597e-02,  4.9606e-02, -7.7988e-02],\n",
       "                        [ 7.8404e-02,  4.4082e-02, -1.2753e-02, -8.0020e-02, -5.1132e-02],\n",
       "                        [ 2.0292e-02, -6.4361e-02, -9.8465e-03,  4.0963e-02, -8.1460e-02],\n",
       "                        [-6.2723e-02, -1.3218e-03, -2.4665e-02,  5.4457e-02,  6.8831e-02]],\n",
       "              \n",
       "                       [[-9.7869e-03,  4.8758e-02, -5.5061e-02,  9.2646e-03,  1.4935e-02],\n",
       "                        [-5.5356e-02,  7.3933e-02, -4.3965e-02,  5.2663e-02, -1.2537e-02],\n",
       "                        [-6.5263e-02,  1.7747e-02, -8.8908e-03, -3.9190e-02,  7.9733e-02],\n",
       "                        [ 6.6593e-05,  3.9522e-02,  5.0150e-02, -8.5450e-03, -5.1364e-02],\n",
       "                        [ 5.4406e-02, -4.2007e-02,  5.2807e-03, -2.9000e-02, -7.6119e-02]],\n",
       "              \n",
       "                       [[-1.3181e-04, -8.0693e-02, -3.6091e-02, -5.5314e-02, -4.4934e-02],\n",
       "                        [ 1.3555e-02,  3.8632e-02, -7.4863e-02,  7.2490e-02,  6.3429e-02],\n",
       "                        [ 3.4249e-02,  3.8894e-02, -2.5450e-02, -3.6379e-02,  4.1159e-02],\n",
       "                        [ 8.1467e-02, -2.1877e-02,  4.9034e-02,  7.0600e-02,  1.7089e-02],\n",
       "                        [-7.0959e-02, -3.9106e-02,  4.3022e-04, -4.9529e-02,  4.7862e-02]],\n",
       "              \n",
       "                       [[-2.6792e-02,  3.1136e-02, -1.6351e-02,  7.1833e-02, -6.2771e-02],\n",
       "                        [ 5.4260e-02,  2.2801e-02,  6.7677e-04,  4.6201e-02, -6.7874e-02],\n",
       "                        [-2.4627e-02,  3.8045e-03, -3.3760e-02, -6.1510e-02,  8.1555e-02],\n",
       "                        [ 5.3756e-03, -6.2117e-02, -7.1439e-02,  2.3620e-02, -4.8765e-02],\n",
       "                        [-6.0917e-02,  2.8024e-02,  1.8521e-02,  2.1180e-03,  5.8863e-02]],\n",
       "              \n",
       "                       [[ 2.7951e-02, -1.8797e-03, -5.2411e-02, -2.1643e-02, -2.2761e-02],\n",
       "                        [ 5.0408e-02, -8.0273e-02, -4.7213e-03,  7.5268e-02,  2.2981e-02],\n",
       "                        [ 1.1571e-02,  5.0012e-02,  6.1055e-02,  4.9528e-03,  2.4137e-02],\n",
       "                        [-3.9903e-02,  5.3313e-02,  7.4756e-02,  1.4491e-02, -4.7734e-02],\n",
       "                        [-4.4237e-02, -1.0676e-02, -7.8730e-02,  7.7871e-02,  2.9544e-02]],\n",
       "              \n",
       "                       [[ 1.7539e-02, -5.1077e-03, -5.9592e-02,  1.9079e-02,  5.8307e-02],\n",
       "                        [ 4.9268e-02,  6.6278e-02,  2.1167e-02,  8.3800e-03,  2.9837e-02],\n",
       "                        [ 6.5762e-02,  4.3393e-02, -5.9061e-02, -6.5666e-02,  4.0220e-02],\n",
       "                        [-4.6738e-02, -2.1228e-02, -5.6810e-02,  1.9762e-02,  1.4842e-02],\n",
       "                        [ 1.2358e-02, -7.9546e-02,  3.7895e-02,  5.8193e-03,  3.4716e-02]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.0791,  0.0701,  0.0616,  0.0028,  0.0575,  0.0726, -0.0577,  0.0248,\n",
       "                      -0.0399, -0.0368, -0.0596,  0.0142, -0.0080,  0.0048,  0.0220, -0.0552])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0372, -0.0371,  0.0275,  ...,  0.0132, -0.0451,  0.0438],\n",
       "                      [ 0.0200, -0.0371, -0.0306,  ..., -0.0098,  0.0445,  0.0324],\n",
       "                      [ 0.0355,  0.0303,  0.0176,  ..., -0.0362,  0.0374,  0.0179],\n",
       "                      ...,\n",
       "                      [-0.0326, -0.0201,  0.0411,  ..., -0.0025, -0.0165, -0.0199],\n",
       "                      [ 0.0386, -0.0108, -0.0463,  ...,  0.0457, -0.0031,  0.0162],\n",
       "                      [-0.0314,  0.0096, -0.0205,  ..., -0.0195,  0.0066,  0.0499]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0239, -0.0489,  0.0026,  0.0224,  0.0015,  0.0092, -0.0485,  0.0061,\n",
       "                       0.0360,  0.0436, -0.0031,  0.0135, -0.0318,  0.0412,  0.0034,  0.0352,\n",
       "                      -0.0499,  0.0075, -0.0230,  0.0153, -0.0279,  0.0047, -0.0095, -0.0148,\n",
       "                       0.0379, -0.0034,  0.0235, -0.0153,  0.0013,  0.0218,  0.0125, -0.0156,\n",
       "                       0.0069, -0.0079, -0.0039, -0.0376,  0.0439,  0.0069, -0.0189, -0.0379,\n",
       "                      -0.0104,  0.0263,  0.0466, -0.0154,  0.0396,  0.0266,  0.0313,  0.0193,\n",
       "                       0.0085,  0.0166,  0.0200, -0.0418,  0.0473,  0.0301,  0.0433, -0.0152,\n",
       "                       0.0088, -0.0106, -0.0080,  0.0277,  0.0244,  0.0281,  0.0411,  0.0152,\n",
       "                       0.0178,  0.0266,  0.0003,  0.0337,  0.0188, -0.0066, -0.0126, -0.0116,\n",
       "                       0.0280,  0.0168, -0.0077,  0.0268, -0.0118, -0.0026,  0.0249, -0.0216,\n",
       "                       0.0128, -0.0148, -0.0152, -0.0024,  0.0048, -0.0017, -0.0214, -0.0085,\n",
       "                      -0.0290,  0.0089, -0.0373,  0.0422,  0.0214, -0.0396,  0.0451,  0.0481,\n",
       "                       0.0162,  0.0442, -0.0239,  0.0358,  0.0087,  0.0386,  0.0259,  0.0069,\n",
       "                       0.0314, -0.0317,  0.0032, -0.0376, -0.0432,  0.0053, -0.0045, -0.0083,\n",
       "                       0.0081, -0.0467, -0.0004, -0.0330, -0.0272,  0.0183, -0.0494, -0.0048])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0274,  0.0039,  0.0761,  ..., -0.0302, -0.0063, -0.0264],\n",
       "                      [-0.0073,  0.0018, -0.0498,  ...,  0.0020,  0.0646, -0.0447],\n",
       "                      [-0.0762, -0.0461, -0.0506,  ..., -0.0609, -0.0587, -0.0270],\n",
       "                      ...,\n",
       "                      [-0.0773, -0.0172, -0.0022,  ..., -0.0318,  0.0811, -0.0123],\n",
       "                      [-0.0017, -0.0454,  0.0906,  ..., -0.0098, -0.0283, -0.0433],\n",
       "                      [-0.0270,  0.0039,  0.0488,  ...,  0.0747, -0.0168, -0.0196]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0399,  0.0781, -0.0611,  0.0091, -0.0664,  0.0430, -0.0219,  0.0595,\n",
       "                       0.0058, -0.0429, -0.0072,  0.0632,  0.0313, -0.0024, -0.0347, -0.0331,\n",
       "                      -0.0893, -0.0097,  0.0110, -0.0534, -0.0909, -0.0523,  0.0862,  0.0673,\n",
       "                       0.0570,  0.0523,  0.0389,  0.0862, -0.0618, -0.0234, -0.0129, -0.0597,\n",
       "                      -0.0575, -0.0365,  0.0005, -0.0059, -0.0789,  0.0840, -0.0701,  0.0906,\n",
       "                      -0.0749, -0.0157,  0.0110, -0.0853,  0.0448,  0.0377, -0.0182, -0.0883,\n",
       "                      -0.0184, -0.0572, -0.0001, -0.0118,  0.0451, -0.0046, -0.0720,  0.0793,\n",
       "                       0.0047,  0.0461, -0.0109,  0.0759,  0.0142, -0.0701,  0.0736, -0.0326,\n",
       "                      -0.0841, -0.0187, -0.0411, -0.0196, -0.0420,  0.0579, -0.0028, -0.0279,\n",
       "                       0.0819, -0.0772, -0.0352, -0.0172, -0.0239,  0.0647,  0.0107,  0.0273,\n",
       "                       0.0071, -0.0822, -0.0665, -0.0028])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0978,  0.1046, -0.1033, -0.0413,  0.0869,  0.0551,  0.0477,  0.0710,\n",
       "                       -0.0979,  0.0585, -0.0635,  0.0090,  0.0240, -0.0415,  0.0209, -0.0451,\n",
       "                       -0.0387,  0.0373,  0.1043, -0.0406, -0.0174, -0.0871, -0.0721, -0.0097,\n",
       "                        0.0142,  0.0813, -0.0038,  0.0666,  0.0184, -0.0239, -0.0381, -0.0819,\n",
       "                       -0.0431,  0.0465,  0.1003, -0.0278,  0.0576, -0.0258,  0.0345,  0.0961,\n",
       "                        0.0532, -0.0929,  0.0591, -0.0461,  0.0359, -0.0204, -0.0978,  0.0152,\n",
       "                       -0.0795,  0.1074,  0.0922, -0.0388, -0.0617, -0.0590, -0.0237, -0.0804,\n",
       "                       -0.0908, -0.0465, -0.0281,  0.0356, -0.0959, -0.0749, -0.0517,  0.0225,\n",
       "                        0.0550, -0.0441,  0.0399, -0.0927,  0.0985, -0.0227, -0.0088,  0.0004,\n",
       "                        0.0482,  0.0073, -0.0821, -0.0949, -0.0146,  0.0321,  0.0985,  0.0616,\n",
       "                       -0.0621, -0.0376, -0.1076,  0.0530],\n",
       "                      [-0.0809,  0.0410, -0.0389,  0.0173, -0.0123,  0.0681, -0.0414, -0.0613,\n",
       "                       -0.0522,  0.1006, -0.0539, -0.0122,  0.1049,  0.0453,  0.0098,  0.0711,\n",
       "                       -0.0138, -0.0475, -0.0442, -0.0445, -0.0750, -0.0625, -0.0461,  0.0511,\n",
       "                        0.0425, -0.0768, -0.0547,  0.0401,  0.0944,  0.0790,  0.0269,  0.0532,\n",
       "                       -0.1042,  0.0132, -0.0878, -0.0285,  0.1040,  0.0187,  0.0550,  0.0911,\n",
       "                        0.0671,  0.1073,  0.0423,  0.0569,  0.1011, -0.0759,  0.0076,  0.0703,\n",
       "                        0.0857,  0.0019, -0.0684, -0.0261, -0.0752,  0.0066,  0.1030,  0.0272,\n",
       "                        0.0298,  0.0012,  0.0562,  0.0114,  0.0496, -0.0180,  0.0277,  0.0965,\n",
       "                       -0.0025, -0.0565, -0.0289,  0.0783, -0.0851, -0.1087, -0.0687, -0.0635,\n",
       "                       -0.0108, -0.0646,  0.0933,  0.0348, -0.0527,  0.0568, -0.0068,  0.0440,\n",
       "                       -0.0554, -0.0822,  0.0237, -0.1015],\n",
       "                      [-0.0379, -0.0166, -0.0355,  0.0105,  0.0187, -0.0899, -0.0611,  0.0577,\n",
       "                       -0.0922,  0.0080, -0.0202, -0.0908,  0.0669,  0.0703, -0.0218, -0.0858,\n",
       "                        0.0198,  0.0855,  0.0180,  0.0092,  0.0585,  0.0545,  0.0363, -0.0915,\n",
       "                        0.0225, -0.0846, -0.0007, -0.0573, -0.0915, -0.0127,  0.0261, -0.0919,\n",
       "                        0.0337,  0.0291, -0.0631,  0.0914,  0.0171, -0.1000,  0.0353,  0.0401,\n",
       "                        0.0063,  0.0628,  0.0233, -0.0259,  0.0703,  0.0389,  0.0659,  0.0047,\n",
       "                        0.0148, -0.0247,  0.0204,  0.0120, -0.0843, -0.1011, -0.0618, -0.0598,\n",
       "                       -0.0478,  0.1017, -0.1011,  0.0421,  0.1055,  0.0269,  0.0113, -0.0667,\n",
       "                        0.0711,  0.0790,  0.0999,  0.0134, -0.0737, -0.0514, -0.0792,  0.0528,\n",
       "                        0.0538, -0.0979,  0.0917, -0.0916,  0.0500, -0.0009,  0.0772,  0.0006,\n",
       "                        0.0317,  0.0061,  0.0465, -0.0730],\n",
       "                      [-0.0159, -0.0222, -0.0309, -0.0547,  0.0911, -0.0049, -0.0127,  0.0522,\n",
       "                        0.0111, -0.0069, -0.0801, -0.0323, -0.0145,  0.0226, -0.0698, -0.0661,\n",
       "                       -0.0422, -0.1051, -0.0932, -0.1067,  0.0493,  0.0063,  0.0037,  0.0460,\n",
       "                       -0.0913,  0.0692, -0.0733,  0.0841,  0.0523, -0.0612,  0.0643, -0.0835,\n",
       "                       -0.0517, -0.0477,  0.1087,  0.0952, -0.0778,  0.0782,  0.0275,  0.0310,\n",
       "                       -0.0814,  0.0431, -0.0664, -0.1006,  0.0608, -0.0036, -0.0890,  0.0103,\n",
       "                       -0.1087, -0.0577, -0.0201, -0.0596, -0.0735,  0.0734,  0.0214, -0.1017,\n",
       "                       -0.0810,  0.0031,  0.0163,  0.0731,  0.0183,  0.0529,  0.0632, -0.0900,\n",
       "                        0.0454, -0.0974,  0.0187, -0.0092, -0.0333,  0.0385,  0.0560, -0.0467,\n",
       "                        0.0141, -0.0287, -0.0189,  0.0554, -0.0625, -0.0347,  0.0492,  0.0278,\n",
       "                        0.0379,  0.0773,  0.1064,  0.0302],\n",
       "                      [ 0.0073,  0.0946, -0.0118,  0.0478,  0.0845, -0.0643, -0.0713,  0.1016,\n",
       "                        0.0352,  0.0695,  0.1021,  0.0917,  0.0902,  0.1065,  0.0696,  0.0539,\n",
       "                       -0.0296,  0.0721, -0.0765, -0.0569, -0.0144,  0.0975, -0.0005, -0.0306,\n",
       "                       -0.0830, -0.0143,  0.0119,  0.0406, -0.0967,  0.0993,  0.0940, -0.0098,\n",
       "                        0.0040,  0.0829,  0.0676, -0.0498,  0.0148,  0.1080,  0.0002,  0.0021,\n",
       "                        0.0873,  0.0598,  0.0342,  0.0156, -0.1032,  0.0101, -0.0482, -0.0610,\n",
       "                       -0.0859, -0.0248,  0.0983, -0.0171,  0.0824, -0.0972, -0.0494, -0.0469,\n",
       "                       -0.0039, -0.0305,  0.0113,  0.0352,  0.0194,  0.0775,  0.0613,  0.0902,\n",
       "                        0.1028, -0.0376, -0.0105, -0.0909,  0.0315, -0.0529,  0.0657, -0.0819,\n",
       "                        0.1023, -0.0364,  0.0687,  0.0670, -0.0343, -0.0813,  0.0907, -0.0596,\n",
       "                        0.0786, -0.0393,  0.0652,  0.0882],\n",
       "                      [ 0.0978, -0.0890,  0.0876,  0.0930,  0.0845, -0.0174,  0.0710, -0.1083,\n",
       "                        0.0743,  0.0094, -0.0468, -0.0538, -0.0002,  0.0167,  0.1027,  0.0321,\n",
       "                        0.0808,  0.0267,  0.0128, -0.0670, -0.0501,  0.0319, -0.0830, -0.0218,\n",
       "                        0.0029, -0.0993, -0.0805,  0.0691,  0.0347,  0.0740, -0.0309, -0.0228,\n",
       "                       -0.0086,  0.1015, -0.0872,  0.0302, -0.0516,  0.0657, -0.0611,  0.0951,\n",
       "                        0.0222, -0.1041, -0.0111, -0.0516,  0.0896, -0.0174,  0.0813,  0.0774,\n",
       "                        0.0688,  0.0561,  0.0940,  0.0657,  0.0972,  0.0209,  0.0409, -0.0620,\n",
       "                        0.0602,  0.0193,  0.0601, -0.0788, -0.0921,  0.0393, -0.0748,  0.0199,\n",
       "                        0.0376, -0.1047,  0.1009,  0.0213, -0.0201,  0.0043,  0.0745,  0.0105,\n",
       "                       -0.0116, -0.0397,  0.0046,  0.0719,  0.0960,  0.0779, -0.0413, -0.0736,\n",
       "                       -0.0791, -0.0964,  0.0430,  0.0948],\n",
       "                      [ 0.0036,  0.0021,  0.0485,  0.0602, -0.0181, -0.0123, -0.0997,  0.0315,\n",
       "                       -0.0469, -0.0789, -0.0541,  0.0767,  0.0488,  0.0145, -0.0266, -0.0613,\n",
       "                       -0.0541,  0.0287, -0.0564, -0.0629,  0.0093, -0.0279,  0.0718,  0.0804,\n",
       "                        0.0210,  0.0631,  0.0560, -0.0165, -0.0663,  0.0444, -0.0578,  0.0906,\n",
       "                       -0.0691, -0.0331, -0.1071, -0.0205, -0.0770,  0.0833,  0.0300,  0.0322,\n",
       "                        0.0317, -0.0706, -0.0262,  0.0294,  0.0121,  0.0056, -0.0387, -0.0344,\n",
       "                        0.0847,  0.0171, -0.0066, -0.0525, -0.0338, -0.0614,  0.0812, -0.0950,\n",
       "                        0.0728, -0.0135, -0.0195, -0.0257,  0.0697,  0.0719, -0.0089,  0.1009,\n",
       "                        0.0797,  0.0281, -0.0569, -0.0418, -0.0758,  0.0018,  0.0652, -0.0625,\n",
       "                        0.0175,  0.0722, -0.0326,  0.0321,  0.0428,  0.0350,  0.0198, -0.0088,\n",
       "                        0.0782, -0.0099,  0.0158, -0.0107],\n",
       "                      [-0.0266, -0.0565,  0.1026,  0.0589,  0.0825, -0.0608, -0.0882, -0.0573,\n",
       "                        0.0692,  0.0841, -0.0619,  0.0601, -0.0135,  0.0874, -0.0257,  0.1061,\n",
       "                        0.0548,  0.0586, -0.0508,  0.0707,  0.0505,  0.0548,  0.0587,  0.0293,\n",
       "                        0.0795, -0.0014, -0.0030, -0.0133, -0.0532,  0.0619,  0.0997, -0.0632,\n",
       "                       -0.0026, -0.0877, -0.0909,  0.0727, -0.0798, -0.0168,  0.0979, -0.0770,\n",
       "                       -0.0893, -0.0802, -0.0204, -0.0734, -0.0996,  0.0230, -0.0954, -0.0606,\n",
       "                       -0.0376, -0.0598, -0.0208,  0.0316, -0.0196,  0.0276,  0.0974,  0.0277,\n",
       "                       -0.0380, -0.0118, -0.0119, -0.1085,  0.0913,  0.1034, -0.1090,  0.0354,\n",
       "                        0.0648,  0.0835,  0.0257,  0.0612,  0.0488,  0.0010,  0.0288, -0.1085,\n",
       "                        0.0483, -0.1010, -0.0993,  0.0498, -0.0799,  0.0976, -0.0443,  0.0936,\n",
       "                        0.0134, -0.0325,  0.0129, -0.0141],\n",
       "                      [-0.0962,  0.0268,  0.0411, -0.0086, -0.0570, -0.0966, -0.0094,  0.0906,\n",
       "                        0.0912,  0.0006,  0.0259, -0.0926, -0.0036, -0.0522,  0.0390,  0.0421,\n",
       "                        0.0733,  0.0440, -0.0977,  0.0685,  0.0262,  0.0106,  0.0497, -0.0070,\n",
       "                        0.0391, -0.1086,  0.0212, -0.0704, -0.0454, -0.0474,  0.0762, -0.1072,\n",
       "                        0.1052,  0.0275, -0.0380,  0.0203, -0.0752,  0.0245,  0.1012, -0.0080,\n",
       "                        0.0841, -0.0456,  0.0275,  0.0803,  0.0291, -0.0555,  0.1027,  0.0901,\n",
       "                        0.0398, -0.0484,  0.0636, -0.0921, -0.0655,  0.0353, -0.0117,  0.0066,\n",
       "                        0.0304,  0.1057,  0.0064, -0.0186, -0.0305,  0.0516, -0.0950, -0.0785,\n",
       "                       -0.0716, -0.0811,  0.1039, -0.0215,  0.0691,  0.0211, -0.0107,  0.1025,\n",
       "                       -0.0421, -0.0109,  0.0059,  0.0349, -0.0479, -0.0782,  0.0588,  0.0521,\n",
       "                       -0.1085,  0.0580,  0.0610,  0.0280],\n",
       "                      [ 0.0585, -0.0887, -0.0688,  0.0467, -0.0842,  0.0519, -0.0262,  0.1049,\n",
       "                       -0.0038,  0.0309, -0.0588,  0.0802,  0.0495, -0.0453,  0.0426,  0.0099,\n",
       "                       -0.0505,  0.0306, -0.0921,  0.0810, -0.0372,  0.0748,  0.1035, -0.0610,\n",
       "                        0.1045, -0.0503, -0.0366,  0.0910,  0.0070,  0.1031,  0.0708, -0.0121,\n",
       "                       -0.0057,  0.0975,  0.0426, -0.0085, -0.0074, -0.0617,  0.0484,  0.0009,\n",
       "                       -0.0992, -0.0527,  0.0984,  0.0500,  0.0413,  0.0967,  0.0020, -0.0207,\n",
       "                        0.0245, -0.0020,  0.0628, -0.0739, -0.0500,  0.0490,  0.0156, -0.0975,\n",
       "                        0.1087, -0.0024, -0.0919,  0.0911, -0.0315,  0.0891, -0.0257, -0.0271,\n",
       "                        0.0848,  0.0715,  0.0715, -0.0856,  0.0409,  0.0464,  0.1042, -0.0965,\n",
       "                       -0.0006, -0.0913, -0.0018,  0.0685,  0.0455, -0.0586, -0.0359,  0.0744,\n",
       "                       -0.0931, -0.0298,  0.0276, -0.0329]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0718, -0.0075, -0.0050, -0.0840,  0.0552,  0.0484, -0.0493,  0.0943,\n",
       "                      -0.0772,  0.0015]))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading Model for Inference\n",
    "\n",
    "Save/Load state_dict (Recommended)\n",
    "\n",
    "### Save:\n",
    "`torch.save(model.state_dict(), PATH)`\n",
    "\n",
    "### Load:\n",
    "``model = TheModelClass(*args, **kwargs)``\n",
    "\n",
    "``model.load_state_dict(torch.load(PATH))``\n",
    "\n",
    "`model.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../../../../MEGA/DatabaseLocal/myNet.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When saving a model for inference**, it is only necessary to save the trained model’s learned parameters. Saving the model’s state_dict with the torch.save() function will give you the most flexibility for restoring the model later, which is why it is the recommended method for saving models.\n",
    "\n",
    "A common PyTorch convention is to save models using either a .pt or .pth file extension.\n",
    "\n",
    "Remember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    "\n",
    "#### NOTE\n",
    "\n",
    "Notice that the load_state_dict() function takes a dictionary object, NOT a path to a saved object. This means that you must deserialize the saved state_dict before you pass it to the load_state_dict() function. For example, you CANNOT load using model.load_state_dict(PATH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TheModelClass()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Entire Model\n",
    "#### Save:\n",
    "\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load:\n",
    "\n",
    "#### Model class must be defined somewhere\n",
    "\n",
    "model = torch.load(PATH)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Python’s pickle module. **The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved**. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors.\n",
    "\n",
    "A common PyTorch convention is to save models using either a .pt or .pth file extension.\n",
    "\n",
    "Remember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading a General Checkpoint for Inference and/or Resuming Training\n",
    "\n",
    "#### Save:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = TheModelClass()\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
