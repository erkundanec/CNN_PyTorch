{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module version used\n",
    "\n",
    "- torch 1.4\n",
    "- numpy 1.18.1\n",
    "- CPython 3.6.9\n",
    "- IPython 7.10.2\n",
    "- numpy     1.17.4\n",
    "- PIL.Image 6.2.1\n",
    "- pandas    0.25.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Runs on CPU or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional ResNet and Residual Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this example does not implement a really deep ResNet as described in literature but rather illustrates how the residual blocks described in He et al. [1] can be implemented in PyTorch.\n",
    "\n",
    "- [1] He, Kaiming, et al. \"Deep residual learning for image recognition.\" *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://analyticsindiamag.com/why-resnets-are-a-major-breakthrough-in-image-processing/\n",
    "\n",
    "Deep convolutional networks have led to remarkable breakthroughs for image classification. Driven by the significance of convolutional neural network, the residual network (ResNet) was created. ResNet was designed by Kaiming He in 2015 in a paper titled Deep Residual Learning for Image Recognition. In this paper, he discussed a model built by his team which bagged the ImageNet challenges in all the domains such as classification, detection, and localisation.\n",
    "\n",
    "## ResNet: What Does ‘Residual’ Mean?\n",
    "Residual is nothing but the error.\n",
    "\n",
    "Let us say that you are asked to predict the weight of ten apples, just by looking at them. If the actual weight of those apples is 3 kilos, and you have predicted it as 4 kilos, then the residual is -1 (kilos). Or, if you predicted the weight of the apples as 1 kilo, then the residual in this case would be +2. Therefore, the residual is the amount or number by which you have to change your prediction to meet the actual value.\n",
    "\n",
    "This can be represented in a small flowchart:\n",
    "\n",
    "<img src=\"../imgs/resnet_basic.png\" alt=\"Drawing\" style=\"width: 220px;\"/>\n",
    "\n",
    "Here, X is our prediction and we want the value to be equal to the Actual value. Since it is off by a small margin, the residual function residual() will compute and produce the residual of the model to match the predicted value with the Actual value. When or if  X = Actual, then the function residual(X) will be zero. The identity function just copies the value X.\n",
    "\n",
    "### What Does ResNet Do?\n",
    "The main goal of the residual network is to build a deeper neural network. We can have two intuitions based on this:\n",
    "\n",
    "As we keep going deeper into implementing large amount of layers, one should make sure not to degrade the accuracy and error rate. This can be handled by identity mapping.\n",
    "Keep learning the residuals to match the predicted with the actual\n",
    "These are the functions of a Residual Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03906a32ba3847b2bf66cf1cce71e6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../MEGA/DatabaseLocal/MNIST/raw/train-images-idx3-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e615585a904577aaf412711958f2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../MEGA/DatabaseLocal/MNIST/raw/train-labels-idx1-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd414484fbb42658cba331bd7d174c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../MEGA/DatabaseLocal/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624443acec394bd8bc154c2fda70e904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../MEGA/DatabaseLocal/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../../MEGA/DatabaseLocal/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 123\n",
    "learning_rate = 0.01\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "\n",
    "# Architecture\n",
    "num_classes = 10\n",
    "\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "serverAvailable = \"no\"\n",
    "if serverAvailable == \"yes\":\n",
    "    datapath = \"../database/\"\n",
    "else:\n",
    "    datapath = '../../../MEGA/DatabaseLocal/'\n",
    "    \n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root=datapath, \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=datapath, \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet with identity blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements the residual blocks with skip connections such that the input passed via the shortcut matches the dimensions of the main path's output, which allows the network to learn identity functions. Such a residual block is illustrated below:\n",
    "\n",
    "![](images/resnets/resnet-ex-1-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #########################\n",
    "        ### 1st residual block\n",
    "        #########################\n",
    "        # 28x28x1 => 28x28x4\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                      out_channels=4,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)\n",
    "        self.conv_1_bn = torch.nn.BatchNorm2d(4)\n",
    "                                    \n",
    "        # 28x28x4 => 28x28x1\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=4,\n",
    "                                      out_channels=1,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1)   \n",
    "        self.conv_2_bn = torch.nn.BatchNorm2d(1)\n",
    "        \n",
    "        \n",
    "        #########################\n",
    "        ### 2nd residual block\n",
    "        #########################\n",
    "        # 28x28x1 => 28x28x4\n",
    "        self.conv_3 = torch.nn.Conv2d(in_channels=1,\n",
    "                                      out_channels=4,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)\n",
    "        self.conv_3_bn = torch.nn.BatchNorm2d(4)\n",
    "                                    \n",
    "        # 28x28x4 => 28x28x1\n",
    "        self.conv_4 = torch.nn.Conv2d(in_channels=4,\n",
    "                                      out_channels=1,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1)   \n",
    "        self.conv_4_bn = torch.nn.BatchNorm2d(1)\n",
    "\n",
    "        #########################\n",
    "        ### Fully connected\n",
    "        #########################        \n",
    "        self.linear_1 = torch.nn.Linear(28*28*1, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #########################\n",
    "        ### 1st residual block\n",
    "        #########################\n",
    "        shortcut = x\n",
    "        \n",
    "        out = self.conv_1(x)\n",
    "        out = self.conv_1_bn(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = self.conv_2_bn(out)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #########################\n",
    "        ### 2nd residual block\n",
    "        #########################\n",
    "        \n",
    "        shortcut = out\n",
    "        \n",
    "        out = self.conv_3(out)\n",
    "        out = self.conv_3_bn(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv_4(out)\n",
    "        out = self.conv_4_bn(out)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #########################\n",
    "        ### Fully connected\n",
    "        #########################   \n",
    "        logits = self.linear_1(out.view(-1, 28*28*1))\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "torch.manual_seed(random_seed)\n",
    "model = ConvNet(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 000/469 | Cost: 2.6090\n",
      "Epoch: 001/003 | Batch 050/469 | Cost: 0.4669\n",
      "Epoch: 001/003 | Batch 100/469 | Cost: 0.4389\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model = model.eval() # eval mode to prevent upd. batchnorm params during inference\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader)))\n",
    "\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet with convolutional blocks for resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements the residual blocks with skip connections such that the input passed via the shortcut matches is resized to dimensions of the main path's output. Such a residual block is illustrated below:\n",
    "\n",
    "![](images/resnets/resnet-ex-1-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #########################\n",
    "        ### 1st residual block\n",
    "        #########################\n",
    "        # 28x28x1 => 14x14x4 \n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                      out_channels=4,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1)\n",
    "        self.conv_1_bn = torch.nn.BatchNorm2d(4)\n",
    "                                    \n",
    "        # 14x14x4 => 14x14x8\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=4,\n",
    "                                      out_channels=8,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)   \n",
    "        self.conv_2_bn = torch.nn.BatchNorm2d(8)\n",
    "        \n",
    "        # 28x28x1 => 14x14x8\n",
    "        self.conv_shortcut_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                               out_channels=8,\n",
    "                                               kernel_size=(1, 1),\n",
    "                                               stride=(2, 2),\n",
    "                                               padding=0)   \n",
    "        self.conv_shortcut_1_bn = torch.nn.BatchNorm2d(8)\n",
    "        \n",
    "        #########################\n",
    "        ### 2nd residual block\n",
    "        #########################\n",
    "        # 14x14x8 => 7x7x16 \n",
    "        self.conv_3 = torch.nn.Conv2d(in_channels=8,\n",
    "                                      out_channels=16,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1)\n",
    "        self.conv_3_bn = torch.nn.BatchNorm2d(16)\n",
    "                                    \n",
    "        # 7x7x16 => 7x7x32\n",
    "        self.conv_4 = torch.nn.Conv2d(in_channels=16,\n",
    "                                      out_channels=32,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)   \n",
    "        self.conv_4_bn = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        # 14x14x8 => 7x7x32 \n",
    "        self.conv_shortcut_2 = torch.nn.Conv2d(in_channels=8,\n",
    "                                               out_channels=32,\n",
    "                                               kernel_size=(1, 1),\n",
    "                                               stride=(2, 2),\n",
    "                                               padding=0)   \n",
    "        self.conv_shortcut_2_bn = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        #########################\n",
    "        ### Fully connected\n",
    "        #########################        \n",
    "        self.linear_1 = torch.nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #########################\n",
    "        ### 1st residual block\n",
    "        #########################\n",
    "        shortcut = x\n",
    "        \n",
    "        out = self.conv_1(x) # 28x28x1 => 14x14x4 \n",
    "        out = self.conv_1_bn(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv_2(out) # 14x14x4 => 714x14x8\n",
    "        out = self.conv_2_bn(out)\n",
    "        \n",
    "        # match up dimensions using a linear function (no relu)\n",
    "        shortcut = self.conv_shortcut_1(shortcut)\n",
    "        shortcut = self.conv_shortcut_1_bn(shortcut)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #########################\n",
    "        ### 2nd residual block\n",
    "        #########################\n",
    "        \n",
    "        shortcut = out\n",
    "        \n",
    "        out = self.conv_3(out) # 14x14x8 => 7x7x16 \n",
    "        out = self.conv_3_bn(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv_4(out) # 7x7x16 => 7x7x32\n",
    "        out = self.conv_4_bn(out)\n",
    "        \n",
    "        # match up dimensions using a linear function (no relu)\n",
    "        shortcut = self.conv_shortcut_2(shortcut)\n",
    "        shortcut = self.conv_shortcut_2_bn(shortcut)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #########################\n",
    "        ### Fully connected\n",
    "        #########################   \n",
    "        logits = self.linear_1(out.view(-1, 7*7*32))\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "torch.manual_seed(random_seed)\n",
    "model = ConvNet(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model = model.eval() # eval mode to prevent upd. batchnorm params during inference\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet with convolutional blocks for resizing (using a helper class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same network as above but uses a `ResidualBlock` helper class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        \n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=channels[0],\n",
    "                                      out_channels=channels[1],\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(2, 2),\n",
    "                                      padding=1)\n",
    "        self.conv_1_bn = torch.nn.BatchNorm2d(channels[1])\n",
    "                                    \n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=channels[1],\n",
    "                                      out_channels=channels[2],\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=0)   \n",
    "        self.conv_2_bn = torch.nn.BatchNorm2d(channels[2])\n",
    "\n",
    "        self.conv_shortcut_1 = torch.nn.Conv2d(in_channels=channels[0],\n",
    "                                               out_channels=channels[2],\n",
    "                                               kernel_size=(1, 1),\n",
    "                                               stride=(2, 2),\n",
    "                                               padding=0)   \n",
    "        self.conv_shortcut_1_bn = torch.nn.BatchNorm2d(channels[2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        \n",
    "        out = self.conv_1(x)\n",
    "        out = self.conv_1_bn(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = self.conv_2_bn(out)\n",
    "        \n",
    "        # match up dimensions using a linear function (no relu)\n",
    "        shortcut = self.conv_shortcut_1(shortcut)\n",
    "        shortcut = self.conv_shortcut_1_bn(shortcut)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.residual_block_1 = ResidualBlock(channels=[1, 4, 8])\n",
    "        self.residual_block_2 = ResidualBlock(channels=[8, 16, 32])\n",
    "    \n",
    "        self.linear_1 = torch.nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.residual_block_1.forward(x)\n",
    "        out = self.residual_block_2.forward(out)\n",
    "         \n",
    "        logits = self.linear_1(out.view(-1, 7*7*32))\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "torch.manual_seed(random_seed)\n",
    "model = ConvNet(num_classes=num_classes)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_dataset)//batch_size, cost))\n",
    "\n",
    "    model = model.eval() # eval mode to prevent upd. batchnorm params during inference\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
